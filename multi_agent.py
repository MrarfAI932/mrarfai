#!/usr/bin/env python3
"""
MRARFAI Multi-Agent System v2.1 (CrewAI + Memory + HITL)
==========================================================
åŸºäº CrewAI æ¡†æ¶çš„ä¸“å®¶å›¢é˜Ÿåä½œç³»ç»Ÿ

v2.1 æ–°å¢ï¼š
  âœ… Agent è®°å¿† â€” è®°ä½ä¹‹å‰åˆ†æï¼Œå¤šè½®æ·±å…¥å¯¹è¯
  âœ… Human-in-the-loop â€” é£æ§å‘ç°é«˜é£é™©æ—¶æš‚åœç­‰äººç¡®è®¤

4 Agents: åˆ†æå¸ˆ + é£æ§ + ç­–ç•¥å¸ˆ + æŠ¥å‘Šå‘˜
"""

import json
import os
from datetime import datetime
from typing import Optional
from collections import deque

# CrewAI å¯¼å…¥
try:
    from crewai import Agent, Task, Crew, Process
    from crewai.tools import BaseTool
    from crewai import LLM
    HAS_CREWAI = True
except Exception:
    HAS_CREWAI = False


# ============================================================
# Agent è®°å¿†ç³»ç»Ÿ
# ============================================================

class AgentMemory:
    """
    å¤šè½®å¯¹è¯è®°å¿†
    - çŸ­æœŸè®°å¿†: æœ€è¿‘Nè½®QAï¼ˆsessionçº§åˆ«ï¼‰
    - å®ä½“è®°å¿†: æåˆ°è¿‡çš„å®¢æˆ·/æ•°æ®ç‚¹
    - åˆ†ææ‘˜è¦: æ¯è½®åˆ†æçš„æ ¸å¿ƒç»“è®º
    """
    
    def __init__(self, max_turns: int = 10):
        self.max_turns = max_turns
        self.conversation_history = deque(maxlen=max_turns)
        self.entity_mentions = {}  # {å®¢æˆ·å: [æåˆ°çš„ä¸Šä¸‹æ–‡]}
        self.analysis_summaries = deque(maxlen=max_turns)
        self.risk_confirmations = {}  # {å®¢æˆ·å: True/False} HITLç¡®è®¤è®°å½•
    
    def add_turn(self, question: str, answer: str, agents_used: list = None, 
                 expert_outputs: dict = None):
        """è®°å½•ä¸€è½®å¯¹è¯"""
        turn = {
            'time': datetime.now().isoformat(),
            'question': question,
            'answer_preview': answer[:200],
            'agents': agents_used or [],
        }
        self.conversation_history.append(turn)
        
        # æå–å®ä½“
        for name_candidate in self._extract_entities(question + " " + answer):
            if name_candidate not in self.entity_mentions:
                self.entity_mentions[name_candidate] = []
            self.entity_mentions[name_candidate].append(question[:50])
        
        # å­˜åˆ†ææ‘˜è¦
        if expert_outputs:
            for expert, output in expert_outputs.items():
                self.analysis_summaries.append({
                    'expert': expert,
                    'summary': output[:150],
                    'question': question[:50],
                })
    
    def add_risk_confirmation(self, customer: str, confirmed: bool):
        """è®°å½•HITLé£é™©ç¡®è®¤"""
        self.risk_confirmations[customer] = {
            'confirmed': confirmed,
            'time': datetime.now().isoformat(),
        }
    
    def get_context_prompt(self) -> str:
        """ç”Ÿæˆè®°å¿†ä¸Šä¸‹æ–‡ï¼Œæ³¨å…¥åˆ°Agent promptä¸­"""
        if not self.conversation_history:
            return ""
        
        lines = ["[ä¹‹å‰çš„å¯¹è¯è®°å¿†]"]
        
        # æœ€è¿‘å¯¹è¯
        for turn in list(self.conversation_history)[-5:]:
            lines.append(f"Q: {turn['question'][:80]}")
            lines.append(f"A: {turn['answer_preview'][:100]}...")
        
        # HITLç¡®è®¤
        if self.risk_confirmations:
            lines.append("\n[é£é™©ç¡®è®¤è®°å½•]")
            for cust, info in self.risk_confirmations.items():
                status = "å·²ç¡®è®¤å…³æ³¨" if info['confirmed'] else "å·²æ ‡è®°ä¸ºä½ä¼˜å…ˆ"
                lines.append(f"- {cust}: {status}")
        
        # é¢‘ç¹æåˆ°çš„å®ä½“
        if self.entity_mentions:
            top_entities = sorted(
                self.entity_mentions.items(), 
                key=lambda x: len(x[1]), reverse=True
            )[:5]
            if top_entities:
                lines.append("\n[ç”¨æˆ·å…³æ³¨çš„é‡ç‚¹å®¢æˆ·]")
                for name, mentions in top_entities:
                    lines.append(f"- {name} (æåˆ°{len(mentions)}æ¬¡)")
        
        return "\n".join(lines)
    
    def _extract_entities(self, text: str) -> list:
        """ç®€å•çš„å®ä½“æå–ï¼ˆå®¢æˆ·åç­‰ï¼‰"""
        # è¿™é‡Œç”¨ç®€å•è§„åˆ™ï¼›å®é™…å¯ä»¥ç”¨NER
        entities = []
        # å¦‚æœæ–‡æœ¬é‡ŒåŒ…å«äº†ä¹‹å‰è§è¿‡çš„å®¢æˆ·åï¼Œè®°å½•
        for name in list(self.entity_mentions.keys()):
            if name in text:
                entities.append(name)
        return entities
    
    def register_known_entities(self, customer_names: list):
        """æ³¨å†Œå·²çŸ¥å®¢æˆ·åç”¨äºå®ä½“è¯†åˆ«"""
        for name in customer_names:
            if name not in self.entity_mentions:
                self.entity_mentions[name] = []
    
    def clear(self):
        self.conversation_history.clear()
        self.entity_mentions.clear()
        self.analysis_summaries.clear()
        self.risk_confirmations.clear()


# å…¨å±€è®°å¿†å®ä¾‹ï¼ˆsessionçº§åˆ«ï¼Œåœ¨chat_tabä¸­é€šè¿‡st.session_stateæŒä¹…åŒ–ï¼‰
_global_memory = AgentMemory()

def get_memory() -> AgentMemory:
    return _global_memory

def set_memory(mem: AgentMemory):
    global _global_memory
    _global_memory = mem


# ============================================================
# Human-in-the-loop æ£€æµ‹
# ============================================================

def detect_hitl_triggers(results: dict, health_scores: list = None) -> list:
    """
    æ£€æµ‹éœ€è¦äººå·¥ç¡®è®¤çš„é«˜é£é™©æƒ…å†µ
    
    è¿”å›: [{
        'customer': str,
        'risk_level': str,
        'reason': str,
        'amount': float,
        'action_required': str,
    }]
    """
    triggers = []
    
    alerts = results.get('æµå¤±é¢„è­¦', [])
    for a in alerts:
        if 'é«˜' in a.get('é£é™©', ''):
            triggers.append({
                'customer': a['å®¢æˆ·'],
                'risk_level': 'ğŸ”´ é«˜é£é™©',
                'reason': a.get('åŸå› ', 'è¶‹åŠ¿ä¸‹æ»‘'),
                'amount': a.get('å¹´åº¦é‡‘é¢', 0),
                'action_required': 'éœ€è¦ç¡®è®¤æ˜¯å¦ç«‹å³å®‰æ’æ‹œè®¿',
            })
    
    if health_scores:
        for s in health_scores:
            if s['ç­‰çº§'] == 'F' and s['å¹´åº¦é‡‘é¢'] > 100:
                # å¤§é¢Fçº§å®¢æˆ·
                triggers.append({
                    'customer': s['å®¢æˆ·'],
                    'risk_level': 'ğŸ”´ å¥åº·åˆ†Fçº§',
                    'reason': f"å¥åº·è¯„åˆ†ä»…{s['æ€»åˆ†']}åˆ†ï¼Œ" + " ".join(s.get('é£é™©æ ‡ç­¾', [])),
                    'amount': s['å¹´åº¦é‡‘é¢'],
                    'action_required': 'éœ€è¦ç¡®è®¤æ˜¯å¦å¯åŠ¨å®¢æˆ·æŒ½å›è®¡åˆ’',
                })
    
    # å»é‡
    seen = set()
    unique = []
    for t in triggers:
        if t['customer'] not in seen:
            seen.add(t['customer'])
            unique.append(t)
    
    return unique


# ============================================================
# è‡ªå®šä¹‰å·¥å…·ï¼šè®©Agentè®¿é—®é”€å”®æ•°æ®
# ============================================================

# æ•°æ®å­˜å‚¨ï¼ˆç‹¬ç«‹äºCrewAIï¼‰
_sales_data_store = {}

def set_sales_data(data_store: dict):
    global _sales_data_store
    _sales_data_store = data_store

def query_sales_data(query: str) -> str:
    ds = _sales_data_store
    if not ds:
        return "æ•°æ®æœªåŠ è½½"
    q = query.lower()
    result = {}
    if any(k in q for k in ['æ€»', 'è¥æ”¶', 'æ”¶å…¥', 'æ¦‚è§ˆ', 'å…¨éƒ¨']):
        result['æ€»è¥æ”¶'] = ds.get('æ€»è¥æ”¶')
        result['æ€»YoY'] = ds.get('æ€»YoY')
        result['æœˆåº¦è¥æ”¶'] = ds.get('æœˆåº¦è¥æ”¶')
        result['æ ¸å¿ƒå‘ç°'] = ds.get('æ ¸å¿ƒå‘ç°')
    if any(k in q for k in ['å®¢æˆ·', 'åˆ†çº§', 'abc', 'æ’å', 'top']):
        result['å®¢æˆ·åˆ†çº§'] = ds.get('å®¢æˆ·åˆ†çº§', [])[:15]
    if any(k in q for k in ['é£é™©', 'æµå¤±', 'é¢„è­¦', 'å¼‚å¸¸']):
        result['æµå¤±é¢„è­¦'] = ds.get('æµå¤±é¢„è­¦')
        result['å¼‚å¸¸æ£€æµ‹'] = ds.get('å¼‚å¸¸æ£€æµ‹', [])[:10]
    if any(k in q for k in ['å¢é•¿', 'æœºä¼š', 'æ½œåŠ›']):
        result['å¢é•¿æœºä¼š'] = ds.get('å¢é•¿æœºä¼š')
    if any(k in q for k in ['ä»·', 'å•ä»·', 'é‡', 'è´¨é‡']):
        result['ä»·é‡åˆ†è§£'] = ds.get('ä»·é‡åˆ†è§£', [])[:10]
    if any(k in q for k in ['åŒºåŸŸ', 'å¸‚åœº', 'åœ°åŒº']):
        result['åŒºåŸŸæ´å¯Ÿ'] = ds.get('åŒºåŸŸæ´å¯Ÿ')
    if any(k in q for k in ['è¡Œä¸š', 'ç«äº‰', 'å¯¹æ ‡', 'åå‹¤', 'é—»æ³°']):
        result['è¡Œä¸šå¯¹æ ‡'] = ds.get('è¡Œä¸šå¯¹æ ‡')
    if any(k in q for k in ['é¢„æµ‹', '2026', 'æœªæ¥', 'å‰æ™¯']):
        result['é¢„æµ‹'] = ds.get('é¢„æµ‹')
    if not result:
        result = {'æ€»è¥æ”¶': ds.get('æ€»è¥æ”¶'), 'æ€»YoY': ds.get('æ€»YoY'), 'æ ¸å¿ƒå‘ç°': ds.get('æ ¸å¿ƒå‘ç°')}
    return json.dumps(result, ensure_ascii=False, indent=1, default=str)[:5000]

# CrewAI Toolï¼ˆä»…åœ¨CrewAIå¯ç”¨æ—¶å®šä¹‰ï¼‰
if HAS_CREWAI:
    class SalesDataTool(BaseTool):
        """è®©AgentæŸ¥è¯¢ç¦¾è‹—é”€å”®æ•°æ®"""
        name: str = "sales_data_query"
        description: str = (
            "æŸ¥è¯¢ç¦¾è‹—é€šè®¯é”€å”®æ•°æ®ã€‚å¯ä»¥æŸ¥è¯¢ï¼šæ€»è¥æ”¶ã€æœˆåº¦è¶‹åŠ¿ã€å®¢æˆ·åˆ†çº§ã€"
            "æµå¤±é¢„è­¦ã€å¢é•¿æœºä¼šã€ä»·é‡åˆ†è§£ã€åŒºåŸŸåˆ†æã€è¡Œä¸šå¯¹æ ‡ã€é¢„æµ‹ã€‚"
        )
        def _run(self, query: str) -> str:
            return query_sales_data(query)


# ============================================================
# Agent è§’è‰²å®šä¹‰
# ============================================================

AGENT_PROFILES = {
    "analyst": {
        "name": "ğŸ“Š æ•°æ®åˆ†æå¸ˆ",
        "emoji": "ğŸ“Š",
        "role": "ç¦¾è‹—é€šè®¯èµ„æ·±æ•°æ®åˆ†æå¸ˆ",
        "goal": "ç²¾å‡†è§£è¯»é”€å”®æ•°æ®ï¼Œç”¨æ•°å­—æ­ç¤ºä¸šåŠ¡çœŸç›¸ï¼Œè¯†åˆ«è¶‹åŠ¿å’Œæ¨¡å¼",
        "backstory": (
            "ä½ åœ¨æ¶ˆè´¹ç”µå­ODMè¡Œä¸šæœ‰15å¹´æ•°æ®åˆ†æç»éªŒï¼Œæ›¾æœåŠ¡åå‹¤ã€é—»æ³°ç­‰å¤´éƒ¨ä¼ä¸šã€‚"
            "ä½ ä»¥æ•°æ®é©±åŠ¨è‘—ç§°ï¼Œæ¯ä¸ªç»“è®ºå¿…é¡»æœ‰æ•°å­—æ”¯æ’‘ã€‚"
            "ä½ æ“…é•¿å‘ç°æœˆåº¦æ³¢åŠ¨è§„å¾‹ã€å®¢æˆ·é›†ä¸­åº¦é£é™©ã€åŒæ¯”ç¯æ¯”å¼‚å¸¸ã€‚"
            "ä½ çš„åˆ†æé£æ ¼ï¼šç²¾å‡†ã€å®¢è§‚ã€é‡åŒ–ã€‚å…ˆç»™ç»“è®ºï¼Œå†ç»™æ•°æ®ã€‚"
        ),
        "keywords": [
            "è¥æ”¶", "æ”¶å…¥", "é‡‘é¢", "å‡ºè´§", "æ•°é‡", "å®¢æˆ·", "åˆ†çº§",
            "ABC", "æ’å", "top", "å æ¯”", "é›†ä¸­", "æœˆåº¦", "å­£åº¦",
            "åŒæ¯”", "ç¯æ¯”", "è¶‹åŠ¿", "æ€»è§ˆ", "æ¦‚è§ˆ", "å¤šå°‘",
            "äº§å“", "ç»“æ„", "åŒºåŸŸ",
        ],
    },
    "risk": {
        "name": "ğŸ›¡ï¸ é£æ§ä¸“å®¶",
        "emoji": "ğŸ›¡ï¸",
        "role": "ç¦¾è‹—é€šè®¯é£é™©æ§åˆ¶ä¸“å®¶",
        "goal": "è¯†åˆ«å®¢æˆ·æµå¤±é£é™©å’Œå¼‚å¸¸æ³¢åŠ¨ï¼Œé‡åŒ–é£é™©é‡‘é¢ï¼Œæä¾›é¢„é˜²æ–¹æ¡ˆ",
        "backstory": (
            "ä½ æ˜¯å‰å®‰æ°¸é£é™©å’¨è¯¢æ€»ç›‘ï¼Œä¸“æ³¨TMTè¡Œä¸šå®¢æˆ·é£é™©ç®¡ç†ã€‚"
            "ä½ å¯¹æ•°æ®å¼‚å¸¸æå…¶æ•æ„Ÿâ€”â€”æ–­å´–å¼ä¸‹è·Œã€è¿ç»­Næœˆè¡°é€€ã€å¤§å®¢æˆ·é›†ä¸­åº¦è¿‡é«˜ï¼Œ"
            "è¿™äº›ä½ ä¸€çœ¼å°±èƒ½çœ‹å‡ºã€‚ä½ çš„é£æ ¼ï¼šç›´è¨€ä¸è®³ï¼Œå‘ç°é—®é¢˜å°±è¯´ã€‚"
            "è¾“å‡ºæ ¼å¼ï¼šé£é™©ç­‰çº§â†’å½±å“é‡‘é¢â†’åŸå› åˆ†æâ†’åº”å¯¹å»ºè®®ã€‚"
            "\n\nâš ï¸ é‡è¦ï¼šå¦‚æœå‘ç°é«˜é£é™©å®¢æˆ·ï¼ˆå¹´åº¦é‡‘é¢>200ä¸‡ä¸”æŒç»­ä¸‹æ»‘ï¼‰ï¼Œ"
            "è¯·åœ¨è¾“å‡ºå¼€å¤´æ ‡è®° [HIGH_RISK_ALERT] å¹¶åˆ—å‡ºå®¢æˆ·åå’Œé‡‘é¢ã€‚"
        ),
        "keywords": [
            "é£é™©", "æµå¤±", "é¢„è­¦", "ä¸‹é™", "ä¸‹æ»‘", "ä¸¢å¤±", "æ–­å´–",
            "å¼‚å¸¸", "æš´è·Œ", "å±é™©", "è­¦å‘Š", "å…³æ³¨", "é—®é¢˜",
            "æ³¢åŠ¨", "åç¦»", "ä¸æ­£å¸¸",
        ],
    },
    "strategist": {
        "name": "ğŸ’¡ ç­–ç•¥å¸ˆ",
        "emoji": "ğŸ’¡",
        "role": "ç¦¾è‹—é€šè®¯æˆ˜ç•¥é¡¾é—®",
        "goal": "å‘ç°å¢é•¿æœºä¼šï¼Œåˆ¶å®šå¯æ‰§è¡Œçš„æˆ˜ç•¥æ–¹æ¡ˆï¼Œä¼˜åŒ–èµ„æºé…ç½®",
        "backstory": (
            "ä½ æ˜¯å‰éº¦è‚¯é”¡TMTè¡Œä¸šåˆä¼™äººï¼Œä¸“æ³¨æ‰‹æœºODM/OEMèµ›é“æˆ˜ç•¥è§„åˆ’ã€‚"
            "ä½ æ“…é•¿ç«äº‰åˆ†æï¼ˆvsåå‹¤/é—»æ³°/é¾™æ——ï¼‰ã€å¢é•¿æœºä¼šè¯†åˆ«ã€"
            "äº§å“ç»„åˆä¼˜åŒ–ã€å®¢æˆ·é’±åŒ…ä»½é¢æå‡ç­–ç•¥ã€‚"
            "ä½ çš„é£æ ¼ï¼šå‰ç»æ€§ã€å®ç”¨ä¸»ä¹‰ã€èšç„¦ROIã€‚å»ºè®®å¿…é¡»å¯æ‰§è¡Œã€‚"
            "è¾“å‡ºæ ¼å¼ï¼šæœºä¼š/æ–¹å‘â†’æ½œåœ¨ä»·å€¼â†’å…·ä½“è¡ŒåŠ¨â†’ä¼˜å…ˆçº§ã€‚"
        ),
        "keywords": [
            "å¢é•¿", "æœºä¼š", "æˆ˜ç•¥", "ç­–ç•¥", "å»ºè®®", "æ–¹å‘", "æŠ•å…¥",
            "ç«äº‰", "å¯¹æ‰‹", "åå‹¤", "é—»æ³°", "é¾™æ——", "è¡Œä¸š", "å¯¹æ ‡",
            "é¢„æµ‹", "forecast", "2026", "æœªæ¥", "å‰æ™¯",
            "CEO", "ç®¡ç†", "å†³ç­–", "ä¼˜åŒ–", "æå‡",
            "ä»·æ ¼", "ä»·é‡", "åˆ©æ¶¦",
        ],
    },
}

REPORTER_PROFILE = {
    "role": "ç¦¾è‹—é€šè®¯é«˜çº§æŠ¥å‘Šæ’°å†™äºº",
    "goal": "ç»¼åˆå¤šä½ä¸“å®¶åˆ†æï¼Œç”Ÿæˆç®€æ´æœ‰åŠ›çš„ç»¼åˆæŠ¥å‘Šï¼Œé€‚åˆCEOé˜…è¯»",
    "backstory": (
        "ä½ æ˜¯å‰FTä¸­æ–‡ç½‘èµ„æ·±ç¼–è¾‘ï¼Œç°ä»»ç¦¾è‹—é€šè®¯æˆ˜ç•¥åˆ†æéƒ¨è´Ÿè´£äººã€‚"
        "ä½ æ“…é•¿å°†å¤æ‚çš„æ•°æ®åˆ†æå’Œå¤šæ–¹è§‚ç‚¹æç‚¼ä¸ºç®¡ç†å±‚å¯ç›´æ¥è¡ŒåŠ¨çš„å»ºè®®ã€‚"
        "è§„åˆ™ï¼š1.ä¸ç®€å•æ‹¼å‡‘ 2.å…ˆæ ¸å¿ƒç»“è®º 3.åˆ†æ¨¡å—å±•å¼€ 4.æœ€åç»™è¡ŒåŠ¨é¡¹ 5.æ§åˆ¶500å­—"
    ),
}


# ============================================================
# è·¯ç”±
# ============================================================

def route_to_agents(question: str) -> list:
    q = question.lower()
    agents_needed = set()
    for agent_id, profile in AGENT_PROFILES.items():
        score = sum(1 for kw in profile['keywords'] if kw in q)
        if score > 0:
            agents_needed.add(agent_id)
    if any(k in q for k in ['CEO', 'æ€»ç»“', 'å…¨é¢', 'æ¦‚è§ˆ', 'æ€ä¹ˆæ ·', 'å»ºè®®', 'æŠ¥å‘Š']):
        agents_needed = {"analyst", "risk", "strategist"}
    if not agents_needed:
        agents_needed = {"analyst", "risk", "strategist"}
    return list(agents_needed)


# ============================================================
# æ•°æ®ä¸Šä¸‹æ–‡
# ============================================================

def build_data_store(data, results, benchmark=None, forecast=None):
    store = {
        'æ€»è¥æ”¶': data.get('æ€»è¥æ”¶', 0),
        'æ€»YoY': data.get('æ€»YoY', {}),
        'æœˆåº¦è¥æ”¶': data.get('æœˆåº¦æ€»è¥æ”¶', []),
        'æ ¸å¿ƒå‘ç°': results.get('æ ¸å¿ƒå‘ç°', []),
        'å®¢æˆ·æ•°': sum(1 for c in data.get('å®¢æˆ·é‡‘é¢', []) if c.get('å¹´åº¦é‡‘é¢', 0) > 0),
        'å®¢æˆ·åˆ†çº§': results.get('å®¢æˆ·åˆ†çº§', [])[:15],
        'æµå¤±é¢„è­¦': results.get('æµå¤±é¢„è­¦', []),
        'å¼‚å¸¸æ£€æµ‹': results.get('MoMå¼‚å¸¸', [])[:10],
        'å¢é•¿æœºä¼š': results.get('å¢é•¿æœºä¼š', []),
        'ä»·é‡åˆ†è§£': results.get('ä»·é‡åˆ†è§£', [])[:10],
        'åŒºåŸŸæ´å¯Ÿ': results.get('åŒºåŸŸæ´å¯Ÿ', {}),
    }
    if benchmark:
        store['è¡Œä¸šå¯¹æ ‡'] = {
            'å¸‚åœºå®šä½': benchmark.get('å¸‚åœºå®šä½', {}),
            'ç«äº‰å¯¹æ ‡': benchmark.get('ç«äº‰å¯¹æ ‡', {}),
            'ç»“æ„æ€§é£é™©': benchmark.get('ç»“æ„æ€§é£é™©', []),
            'æˆ˜ç•¥æœºä¼š': benchmark.get('æˆ˜ç•¥æœºä¼š', []),
        }
    if forecast:
        store['é¢„æµ‹'] = {
            'æ€»è¥æ”¶é¢„æµ‹': forecast.get('æ€»è¥æ”¶é¢„æµ‹', {}),
            'å®¢æˆ·é¢„æµ‹': forecast.get('å®¢æˆ·é¢„æµ‹', [])[:5],
            'æƒ…æ™¯åˆ†æ': forecast.get('é£é™©åœºæ™¯', {}),
        }
    return store


# ============================================================
# LLM
# ============================================================

def _get_llm(provider: str, api_key: str):
    if provider == "deepseek":
        os.environ["OPENAI_API_KEY"] = api_key
        return LLM(
            model="deepseek/deepseek-chat",
            api_key=api_key,
            base_url="https://api.deepseek.com/v1",
            temperature=0.3,
        )
    elif provider == "claude":
        os.environ["ANTHROPIC_API_KEY"] = api_key
        return LLM(
            model="anthropic/claude-sonnet-4-20250514",
            api_key=api_key,
            temperature=0.3,
        )
    return LLM(model="openai/gpt-4o", api_key=api_key, temperature=0.3)


# ============================================================
# ä¸»å…¥å£ (CrewAIç‰ˆ)
# ============================================================

def ask_multi_agent(
    question: str,
    data: dict,
    results: dict,
    benchmark: dict = None,
    forecast: dict = None,
    provider: str = "deepseek",
    api_key: str = "",
    memory: AgentMemory = None,
) -> dict:
    """
    CrewAI Multi-Agent é—®ç­”å…¥å£
    
    è¿”å›: {
        "answer": str,
        "agents_used": list,
        "thinking": list,
        "expert_outputs": dict,
        "hitl_triggers": list,  # éœ€è¦äººå·¥ç¡®è®¤çš„é«˜é£é™©
    }
    """
    
    if not HAS_CREWAI:
        return _ask_fallback(question, data, results, benchmark, forecast, provider, api_key, memory)
    
    # CrewAIæ¡†æ¶å¼€é”€å¤ªå¤§ï¼Œé»˜è®¤ç”¨ç®€åŒ–ç‰ˆï¼ˆåŒæ ·4ä¸“å®¶ï¼Œç›´æ¥è°ƒLLMï¼Œå¿«10å€ï¼‰
    # å¦‚éœ€å¯ç”¨CrewAIåŸç”Ÿæ¨¡å¼ï¼Œå°†ä¸‹é¢è¿™è¡Œæ³¨é‡Šæ‰
    return ask_multi_agent_simple(question, data, results, benchmark, forecast, provider, api_key, memory)
    
    if not api_key:
        return {"answer": "âš ï¸ è¯·å…ˆé…ç½®API Key", "agents_used": [], "thinking": [], 
                "expert_outputs": {}, "hitl_triggers": []}
    
    # è®°å¿†
    mem = memory or get_memory()
    mem_context = mem.get_context_prompt()
    thinking = [f"ğŸ“© æ”¶åˆ°é—®é¢˜ï¼š{question}"]
    if mem_context:
        thinking.append(f"ğŸ§  åŠ è½½äº† {len(mem.conversation_history)} è½®å¯¹è¯è®°å¿†")
    
    # æ•°æ®
    data_store = build_data_store(data, results, benchmark, forecast)
    set_sales_data(data_store)
    
    # æ³¨å†Œå·²çŸ¥å®¢æˆ·ååˆ°è®°å¿†
    for c in data.get('å®¢æˆ·é‡‘é¢', [])[:50]:
        name = c.get('å®¢æˆ·', '')
        if name and len(name) >= 2:
            mem.register_known_entities([name])
    
    # è·¯ç”±
    agents_needed = route_to_agents(question)
    thinking.append(f"ğŸ¯ è°ƒåº¦ {len(agents_needed)} ä¸ªä¸“å®¶")
    
    # LLM
    try:
        llm = _get_llm(provider, api_key)
    except Exception as e:
        return {"answer": f"âš ï¸ LLMé…ç½®å¤±è´¥: {e}", "agents_used": [], "thinking": [],
                "expert_outputs": {}, "hitl_triggers": []}
    
    sales_tool = SalesDataTool()
    
    # æ•°æ®ä¸Šä¸‹æ–‡
    ctx_str = json.dumps(
        {k: v for k, v in data_store.items() if v},
        ensure_ascii=False, indent=1, default=str
    )[:4000]
    
    # è®°å¿†æ³¨å…¥åˆ°prompt
    memory_section = ""
    if mem_context:
        memory_section = f"\n\n[å¯¹è¯è®°å¿†]\n{mem_context}\n"
    
    # åˆ›å»ºAgents
    crew_agents = {}
    
    if "analyst" in agents_needed:
        p = AGENT_PROFILES["analyst"]
        crew_agents["analyst"] = Agent(
            role=p["role"], goal=p["goal"], backstory=p["backstory"],
            tools=[sales_tool], llm=llm, verbose=False, memory=True, max_iter=3,
        )
        thinking.append(f"   ğŸ“Š åˆ†æå¸ˆ å°±ç»ª")
    
    if "risk" in agents_needed:
        p = AGENT_PROFILES["risk"]
        crew_agents["risk"] = Agent(
            role=p["role"], goal=p["goal"], backstory=p["backstory"],
            tools=[sales_tool], llm=llm, verbose=False, memory=True, max_iter=3,
        )
        thinking.append(f"   ğŸ›¡ï¸ é£æ§ å°±ç»ª")
    
    if "strategist" in agents_needed:
        p = AGENT_PROFILES["strategist"]
        crew_agents["strategist"] = Agent(
            role=p["role"], goal=p["goal"], backstory=p["backstory"],
            tools=[sales_tool], llm=llm, verbose=False, memory=True, max_iter=3,
        )
        thinking.append(f"   ğŸ’¡ ç­–ç•¥å¸ˆ å°±ç»ª")
    
    reporter = Agent(
        role=REPORTER_PROFILE["role"], goal=REPORTER_PROFILE["goal"],
        backstory=REPORTER_PROFILE["backstory"],
        llm=llm, verbose=False, memory=True, max_iter=3,
    )
    thinking.append(f"   ğŸ–Šï¸ æŠ¥å‘Šå‘˜ å°±ç»ª")
    
    # åˆ›å»ºTasks
    tasks = []
    task_map = {}
    
    if "analyst" in crew_agents:
        t = Task(
            description=f"åˆ†æç¦¾è‹—é€šè®¯é”€å”®æ•°æ®ã€‚ç”¨æˆ·é—®é¢˜ï¼š{question}\næ•°æ®ï¼š\n{ctx_str}{memory_section}\nè¦æ±‚ï¼šç”¨æ•°å­—è¯´è¯ï¼Œ200å­—å†…ã€‚",
            expected_output="æ•°æ®åˆ†ææŠ¥å‘Š",
            agent=crew_agents["analyst"],
        )
        tasks.append(t); task_map["analyst"] = t
    
    if "risk" in crew_agents:
        t = Task(
            description=f"ä»é£æ§è§’åº¦åˆ†æã€‚ç”¨æˆ·é—®é¢˜ï¼š{question}\næ•°æ®ï¼š\n{ctx_str}{memory_section}\nè¦æ±‚ï¼šå…³æ³¨æµå¤±å’Œå¼‚å¸¸ï¼Œå¦‚æœ‰é«˜é£é™©æ ‡è®°[HIGH_RISK_ALERT]ï¼Œ200å­—å†…ã€‚",
            expected_output="é£é™©è¯„ä¼°æŠ¥å‘Š",
            agent=crew_agents["risk"],
            context=[task_map["analyst"]] if "analyst" in task_map else [],
        )
        tasks.append(t); task_map["risk"] = t
    
    if "strategist" in crew_agents:
        t = Task(
            description=f"ä»æˆ˜ç•¥è§’åº¦åˆ†æã€‚ç”¨æˆ·é—®é¢˜ï¼š{question}\næ•°æ®ï¼š\n{ctx_str}{memory_section}\nè¦æ±‚ï¼šå¯æ‰§è¡Œå»ºè®®ï¼Œèšç„¦ROIï¼Œ200å­—å†…ã€‚",
            expected_output="æˆ˜ç•¥å»ºè®®æŠ¥å‘Š",
            agent=crew_agents["strategist"],
            context=list(task_map.values()),
        )
        tasks.append(t); task_map["strategist"] = t
    
    report_task = Task(
        description=f"ç»¼åˆä¸“å®¶åˆ†æç”ŸæˆCEOæŠ¥å‘Šã€‚åŸå§‹é—®é¢˜ï¼š{question}{memory_section}\næ ¼å¼ï¼šæ ¸å¿ƒç»“è®ºâ†’åˆ†æè¯¦æƒ…(ğŸ“ŠğŸ›¡ï¸ğŸ’¡)â†’ä¸‹ä¸€æ­¥è¡ŒåŠ¨(æœ€å¤š3æ¡)ã€‚500å­—å†…ï¼Œä¸­æ–‡ã€‚",
        expected_output="ç»¼åˆæŠ¥å‘Š",
        agent=reporter,
        context=list(task_map.values()),
    )
    tasks.append(report_task)
    
    # æ‰§è¡Œ
    thinking.append("ğŸš€ Crewå¯åŠ¨...")
    
    try:
        crew = Crew(
            agents=list(crew_agents.values()) + [reporter],
            tasks=tasks, process=Process.sequential,
            verbose=False, memory=True,
        )
        result = crew.kickoff()
        thinking.append("âœ… å®Œæˆ")
        
        # æ”¶é›†è¾“å‡º
        expert_outputs = {}
        agents_used = []
        for aid, task in task_map.items():
            profile = AGENT_PROFILES[aid]
            agents_used.append(profile["name"])
            if hasattr(task, 'output') and task.output:
                expert_outputs[profile["name"]] = str(task.output)
            else:
                expert_outputs[profile["name"]] = "(è¾“å‡ºå·²ä¼ é€’ç»™æŠ¥å‘Šå‘˜)"
        agents_used.append("ğŸ–Šï¸ æŠ¥å‘Šå‘˜")
        
        final_answer = str(result) if result else "åˆ†æå®Œæˆ"
        
        # HITL: æ£€æµ‹é£æ§è¾“å‡ºä¸­çš„é«˜é£é™©æ ‡è®°
        hitl_triggers = []
        risk_output = expert_outputs.get("ğŸ›¡ï¸ é£æ§ä¸“å®¶", "")
        if "[HIGH_RISK_ALERT]" in risk_output or "é«˜é£é™©" in risk_output:
            hitl_triggers = detect_hitl_triggers(results)
            if hitl_triggers:
                thinking.append(f"âš ï¸ HITL: æ£€æµ‹åˆ° {len(hitl_triggers)} ä¸ªé«˜é£é™©éœ€è¦äººå·¥ç¡®è®¤")
        
        # è®°å½•åˆ°è®°å¿†
        mem.add_turn(question, final_answer, agents_used, expert_outputs)
        
        return {
            "answer": final_answer,
            "agents_used": agents_used,
            "thinking": thinking,
            "expert_outputs": expert_outputs,
            "hitl_triggers": hitl_triggers,
        }
    
    except Exception as e:
        thinking.append(f"âŒ å¼‚å¸¸: {str(e)}")
        return _ask_fallback(question, data, results, benchmark, forecast, provider, api_key, memory)


# ============================================================
# é™çº§æ–¹æ¡ˆ
# ============================================================

def _call_llm_raw(system_prompt, user_prompt, provider, api_key):
    if not api_key:
        return "[éœ€è¦API Key]"
    try:
        if provider == "deepseek":
            from openai import OpenAI
            client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
            resp = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "system", "content": system_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.3, max_tokens=800,
            )
            return resp.choices[0].message.content
        elif provider == "claude":
            import anthropic
            client = anthropic.Anthropic(api_key=api_key)
            resp = client.messages.create(
                model="claude-sonnet-4-20250514", max_tokens=800,
                system=system_prompt,
                messages=[{"role": "user", "content": user_prompt}],
            )
            return resp.content[0].text
    except Exception as e:
        return f"[è°ƒç”¨å¤±è´¥: {e}]"


def ask_multi_agent_simple(
    question: str, data: dict, results: dict,
    benchmark=None, forecast=None,
    provider="deepseek", api_key="",
    memory: AgentMemory = None,
) -> dict:
    """ç®€åŒ–ç‰ˆï¼ˆä¸ä¾èµ–CrewAIï¼‰"""
    
    mem = memory or get_memory()
    mem_context = mem.get_context_prompt()
    
    data_store = build_data_store(data, results, benchmark, forecast)
    ctx_json = json.dumps(
        {k: v for k, v in data_store.items() if v},
        ensure_ascii=False, indent=1, default=str
    )[:5000]
    
    agents_needed = route_to_agents(question)
    thinking = [f"ğŸ“© é—®é¢˜ï¼š{question}", f"ğŸ¯ è°ƒåº¦ {len(agents_needed)} ä¸ªä¸“å®¶ (ç®€åŒ–æ¨¡å¼)"]
    if mem_context:
        thinking.append(f"ğŸ§  åŠ è½½ {len(mem.conversation_history)} è½®è®°å¿†")
    
    memory_section = f"\n\n[å¯¹è¯è®°å¿†]\n{mem_context}" if mem_context else ""
    
    expert_outputs = {}
    agents_used = []
    
    for aid in agents_needed:
        profile = AGENT_PROFILES[aid]
        thinking.append(f"{profile['emoji']} {profile['name']} åˆ†æä¸­...")
        
        system = f"ä½ æ˜¯{profile['role']}ã€‚{profile['backstory']}"
        prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\nç¦¾è‹—é”€å”®æ•°æ®ï¼š\n{ctx_json}{memory_section}\n\n200å­—å†…å›ç­”ã€‚"
        
        output = _call_llm_raw(system, prompt, provider, api_key)
        expert_outputs[profile["name"]] = output
        agents_used.append(profile["name"])
        thinking.append(f"{profile['emoji']} å®Œæˆ ({len(output)}å­—)")
    
    # Reporter
    thinking.append("ğŸ–Šï¸ æŠ¥å‘Šå‘˜ç»¼åˆä¸­...")
    all_opinions = "\n---\n".join(f"{n}ï¼š\n{t}" for n, t in expert_outputs.items())
    reporter_sys = f"ä½ æ˜¯{REPORTER_PROFILE['role']}ã€‚{REPORTER_PROFILE['backstory']}"
    report = _call_llm_raw(
        reporter_sys,
        f"é—®é¢˜ï¼š{question}\n\nä¸“å®¶åˆ†æï¼š\n{all_opinions}{memory_section}\n\nç»¼åˆæŠ¥å‘Šï¼Œ500å­—å†…ã€‚",
        provider, api_key,
    )
    agents_used.append("ğŸ–Šï¸ æŠ¥å‘Šå‘˜")
    thinking.append(f"ğŸ–Šï¸ å®Œæˆ")
    
    # HITL
    hitl_triggers = []
    risk_out = expert_outputs.get("ğŸ›¡ï¸ é£æ§ä¸“å®¶", "")
    if "é«˜é£é™©" in risk_out or "[HIGH_RISK_ALERT]" in risk_out:
        hitl_triggers = detect_hitl_triggers(results)
        if hitl_triggers:
            thinking.append(f"âš ï¸ HITL: {len(hitl_triggers)} ä¸ªéœ€ç¡®è®¤")
    
    mem.add_turn(question, report, agents_used, expert_outputs)
    
    return {
        "answer": report,
        "agents_used": agents_used,
        "thinking": thinking,
        "expert_outputs": expert_outputs,
        "hitl_triggers": hitl_triggers,
    }


def _ask_fallback(question, data, results, benchmark, forecast, provider, api_key, memory=None):
    return ask_multi_agent_simple(question, data, results, benchmark, forecast, provider, api_key, memory)
