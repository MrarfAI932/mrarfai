#!/usr/bin/env python3
"""
MRARFAI V9.0 â€” LatentLens Interpretability Layer
====================================================
åŸºäº "LatentLens" (arXiv:2602.07715) + MRARFAI å¯è§‚æµ‹æ€§éœ€æ±‚

æ ¸å¿ƒæ€è·¯:
  å°† Agent å†…éƒ¨çŠ¶æ€æ˜ å°„ä¸ºäººç±»å¯ç†è§£çš„è‡ªç„¶è¯­è¨€è§£é‡Š
  ä¸æ˜¯é»‘ç›’è¾“å‡º â†’ è€Œæ˜¯å±•ç¤º"Agent ä¸ºä»€ä¹ˆè¿™æ ·åˆ†æ"

ä¸‰å±‚è§£é‡Š:
  1. Intent Mapping  â€” é—®é¢˜æ„å›¾è¯†åˆ« + è·¯ç”±è§£é‡Š
  2. Process Trace   â€” æ¨ç†è¿‡ç¨‹è¿½è¸ª + å†³ç­–æ ‘å¯è§†åŒ–
  3. Output Explain  â€” è¾“å‡ºå½’å›  + ç½®ä¿¡åº¦åˆ†è§£

é›†æˆç‚¹:
  - observability.py: æ‰©å±• Langfuse trace åŠ è§£é‡Šå±‚
  - adaptive_gate.py: è§£é‡Šé—¨æ§å†³ç­–(ä¸ºä»€ä¹ˆ skip/light/full)
  - search_engine.py: è§£é‡Šæœç´¢è·¯å¾„é€‰æ‹©
  - reasoning_templates.py: è§£é‡Šæ¨¡æ¿åŒ¹é…é€»è¾‘
  - memory_v9.py: è§£é‡Šè®°å¿†æ£€ç´¢å’ŒæŠ€èƒ½åŒ¹é…
  - ai_narrator.py: é›†æˆåˆ°å™äº‹è¾“å‡º

æ•ˆæœ:
  - æ¯æ¬¡åˆ†æé™„å¸¦"å†³ç­–è§£é‡Š"é¢æ¿
  - ç”¨æˆ·å¯ç‚¹å‡»æŸ¥çœ‹: ä¸ºä»€ä¹ˆé€‰äº†è¿™äº› Agent / ä¸ºä»€ä¹ˆå…³æ³¨è¿™äº›æ•°æ®
  - å®¡è®¡åˆè§„: å®Œæ•´çš„å†³ç­–å½’å› é“¾
"""

import json
import time
import logging
from typing import Optional, Dict, List, Any, Tuple
from dataclasses import dataclass, field
from collections import defaultdict

logger = logging.getLogger("mrarfai.interpret")


# ============================================================
# è§£é‡Šæ•°æ®ç»“æ„
# ============================================================

@dataclass
class IntentExplanation:
    """æ„å›¾è§£é‡Š"""
    original_query: str
    detected_intent: str              # trend / compare / risk / query / forecast
    confidence: float                 # 0-1
    intent_signals: List[Dict]        # è§¦å‘æ„å›¾çš„ä¿¡å·
    route_decision: str               # skip / light / full
    route_reason: str                 # è·¯ç”±åŸå› 
    alternative_intents: List[Dict] = field(default_factory=list)  # å…¶ä»–å¯èƒ½æ„å›¾

@dataclass
class ProcessStep:
    """æ¨ç†è¿‡ç¨‹æ­¥éª¤"""
    step_name: str
    agent_name: str
    action: str                       # åšäº†ä»€ä¹ˆ
    input_summary: str                # è¾“å…¥æ‘˜è¦
    output_summary: str               # è¾“å‡ºæ‘˜è¦
    decision_points: List[Dict] = field(default_factory=list)  # å…³é”®å†³ç­–ç‚¹
    data_accessed: List[str] = field(default_factory=list)      # è®¿é—®çš„æ•°æ®
    elapsed_ms: float = 0
    tokens_used: int = 0

@dataclass
class OutputAttribution:
    """è¾“å‡ºå½’å› """
    claim: str                        # ä¸€ä¸ªå…·ä½“æ–­è¨€
    confidence: float                 # ç½®ä¿¡åº¦
    supporting_data: List[Dict]       # æ”¯æ’‘æ•°æ®
    source_agents: List[str]          # æ¥æº Agent
    memory_used: List[str] = field(default_factory=list)    # ä½¿ç”¨çš„è®°å¿†
    reasoning_chain: str = ""         # æ¨ç†é“¾æ¦‚è¦

@dataclass
class FullExplanation:
    """å®Œæ•´çš„è§£é‡ŠæŠ¥å‘Š"""
    query: str
    intent: IntentExplanation
    process: List[ProcessStep]
    attributions: List[OutputAttribution]
    summary_zh: str = ""              # ä¸­æ–‡æ€»ç»“
    total_elapsed_ms: float = 0
    total_tokens: int = 0
    explanation_cost_pct: float = 0   # è§£é‡Šæœ¬èº«çš„å¼€é”€å æ¯”


# ============================================================
# Intent Mapper â€” æ„å›¾è¯†åˆ«ä¸è§£é‡Š
# ============================================================

class IntentMapper:
    """
    æ„å›¾æ˜ å°„å™¨ â€” è§£é‡Š Agent å¦‚ä½•ç†è§£ç”¨æˆ·é—®é¢˜
    """

    INTENT_PATTERNS = {
        "trend": {
            "keywords": ["è¶‹åŠ¿", "å˜åŒ–", "èµ°åŠ¿", "å¢é•¿", "ä¸‹é™", "æ³¢åŠ¨", "æœˆåº¦", "å­£åº¦"],
            "description": "è¶‹åŠ¿åˆ†æ â€” è¯†åˆ«æ—¶é—´åºåˆ—å˜åŒ–æ¨¡å¼",
        },
        "compare": {
            "keywords": ["å¯¹æ¯”", "æ¯”è¾ƒ", "vs", "å·®å¼‚", "æ’å", "top", "æœ€é«˜", "æœ€ä½"],
            "description": "å¯¹æ¯”åˆ†æ â€” å¤šç»´åº¦æ¨ªå‘æ¯”è¾ƒ",
        },
        "risk": {
            "keywords": ["é£é™©", "å¼‚å¸¸", "ä¸‹æ»‘", "æµå¤±", "é›†ä¸­åº¦", "é¢„è­¦", "å±é™©"],
            "description": "é£é™©æ£€æµ‹ â€” è¯†åˆ«æ½œåœ¨å¨èƒå’Œå¼‚å¸¸",
        },
        "forecast": {
            "keywords": ["é¢„æµ‹", "é¢„ä¼°", "ä¼°è®¡", "æ˜å¹´", "ä¸‹å­£åº¦", "å±•æœ›", "é¢„æœŸ"],
            "description": "é¢„æµ‹åˆ†æ â€” æœªæ¥è¶‹åŠ¿æ¨æ–­",
        },
        "query": {
            "keywords": ["å¤šå°‘", "æ˜¯ä»€ä¹ˆ", "å‡ ä¸ª", "åˆ—å‡º", "æ€»", "æŸ¥è¯¢"],
            "description": "æ•°æ®æŸ¥è¯¢ â€” ç›´æ¥æ£€ç´¢ç‰¹å®šæ•°æ®",
        },
        "strategy": {
            "keywords": ["ç­–ç•¥", "å»ºè®®", "æ€ä¹ˆåŠ", "æœºä¼š", "è¡ŒåŠ¨", "ä¼˜åŒ–"],
            "description": "ç­–ç•¥å»ºè®® â€” åŸºäºæ•°æ®çš„è¡ŒåŠ¨æ–¹æ¡ˆ",
        },
    }

    COMPLEXITY_REASONS = {
        "skip": "é—®é¢˜è¾ƒç®€å•ï¼Œç›´æ¥SQLæŸ¥è¯¢å³å¯ï¼Œæ— éœ€è°ƒç”¨åˆ†æAgent",
        "light": "é—®é¢˜ä¸­ç­‰å¤æ‚ï¼Œéœ€è¦1-2ä¸ªä¸“ä¸šAgentè¿›è¡Œåˆ†æ",
        "full": "é—®é¢˜æ¶‰åŠå¤šç»´åº¦/è·¨é¢†åŸŸåˆ†æï¼Œéœ€è¦å…¨éƒ¨Agentåä½œ",
    }

    def explain_intent(self, query: str,
                       gate_result: Dict = None) -> IntentExplanation:
        """ç”Ÿæˆæ„å›¾è§£é‡Š"""
        # æ£€æµ‹æ„å›¾
        intent_scores = {}
        intent_signals = []

        for intent, config in self.INTENT_PATTERNS.items():
            score = 0
            matched_kws = []
            for kw in config["keywords"]:
                if kw in query:
                    score += 1
                    matched_kws.append(kw)
            if matched_kws:
                intent_scores[intent] = score
                intent_signals.append({
                    "intent": intent,
                    "matched_keywords": matched_kws,
                    "score": score,
                })

        # ä¸»æ„å›¾
        if intent_scores:
            primary = max(intent_scores, key=intent_scores.get)
            max_score = max(intent_scores.values())
            confidence = min(1.0, max_score / 3)
        else:
            primary = "query"
            confidence = 0.3

        # è·¯ç”±è§£é‡Š
        route = "light"
        if gate_result:
            route = gate_result.get("level", "light")
        route_reason = self.COMPLEXITY_REASONS.get(route, "é»˜è®¤è·¯ç”±")

        # å¤‡é€‰æ„å›¾
        alternatives = [
            {"intent": k, "score": v, "desc": self.INTENT_PATTERNS[k]["description"]}
            for k, v in sorted(intent_scores.items(), key=lambda x: -x[1])
            if k != primary
        ][:3]

        return IntentExplanation(
            original_query=query,
            detected_intent=primary,
            confidence=confidence,
            intent_signals=intent_signals,
            route_decision=route,
            route_reason=route_reason,
            alternative_intents=alternatives,
        )


# ============================================================
# Process Tracer â€” æ¨ç†è¿‡ç¨‹è¿½è¸ª
# ============================================================

class ProcessTracer:
    """
    æ¨ç†è¿‡ç¨‹è¿½è¸ªå™¨ â€” è®°å½• Agent æ¯ä¸€æ­¥çš„å†³ç­–

    ä¸ observability.py äº’è¡¥:
      - observability: åº•å±‚ span/trace (æŠ€æœ¯æŒ‡æ ‡)
      - ProcessTracer: é«˜å±‚ "ä¸ºä»€ä¹ˆ" (ä¸šåŠ¡è§£é‡Š)
    """

    def __init__(self):
        self.steps: List[ProcessStep] = []
        self._start_time = time.time()

    def trace_step(self, step_name: str, agent_name: str,
                   action: str, input_summary: str = "",
                   output_summary: str = "",
                   decision_points: List[Dict] = None,
                   data_accessed: List[str] = None,
                   elapsed_ms: float = 0, tokens: int = 0):
        """è®°å½•ä¸€ä¸ªæ¨ç†æ­¥éª¤"""
        self.steps.append(ProcessStep(
            step_name=step_name,
            agent_name=agent_name,
            action=action,
            input_summary=input_summary[:200],
            output_summary=output_summary[:300],
            decision_points=decision_points or [],
            data_accessed=data_accessed or [],
            elapsed_ms=elapsed_ms,
            tokens_used=tokens,
        ))

    def trace_gate_decision(self, query: str, level: str,
                            score: float, agents: List[str]):
        """è¿½è¸ªé—¨æ§å†³ç­–"""
        self.trace_step(
            step_name="é—¨æ§è·¯ç”±",
            agent_name="AdaptiveGate",
            action=f"å¤æ‚åº¦è¯„ä¼° â†’ {level}",
            input_summary=query[:100],
            output_summary=f"åˆ†æ•°={score:.2f}, çº§åˆ«={level}, æ¨èAgent={agents}",
            decision_points=[{
                "point": "å¤æ‚åº¦é˜ˆå€¼",
                "threshold": "skip<0.3, light<0.7, fullâ‰¥0.7",
                "actual": f"{score:.2f} â†’ {level}",
            }],
        )

    def trace_agent_call(self, agent_name: str, question: str,
                         output_preview: str, elapsed_ms: float,
                         tokens: int, template_used: str = ""):
        """è¿½è¸ª Agent è°ƒç”¨"""
        self.trace_step(
            step_name=f"Agentåˆ†æ: {agent_name}",
            agent_name=agent_name,
            action=f"ä½¿ç”¨æ¨¡æ¿ {template_used}" if template_used else "è‡ªç”±åˆ†æ",
            input_summary=question[:100],
            output_summary=output_preview[:200],
            elapsed_ms=elapsed_ms,
            tokens=tokens,
        )

    def trace_memory_recall(self, agent: str, query: str,
                            memories_found: int, skills_matched: int):
        """è¿½è¸ªè®°å¿†æ£€ç´¢"""
        self.trace_step(
            step_name="è®°å¿†æ£€ç´¢",
            agent_name="MemoryV9",
            action=f"ä¸º {agent} æ£€ç´¢è®°å¿†",
            input_summary=query[:80],
            output_summary=f"æ‰¾åˆ° {memories_found} æ¡ç›¸å…³è®°å¿†, {skills_matched} ä¸ªåŒ¹é…æŠ€èƒ½",
        )

    def trace_search(self, strategy: str, branches: int,
                     best_score: float, calls: int):
        """è¿½è¸ªæœç´¢è¿‡ç¨‹"""
        self.trace_step(
            step_name="EnCompassæœç´¢",
            agent_name="SearchEngine",
            action=f"{strategy} æœç´¢",
            output_summary=f"æ¢ç´¢ {branches} æ¡è·¯å¾„, æœ€ä¼˜åˆ† {best_score:.3f}, {calls} æ¬¡LLMè°ƒç”¨",
        )

    def get_trace(self) -> List[ProcessStep]:
        return self.steps

    def to_timeline(self) -> List[Dict]:
        """è½¬æ¢ä¸ºæ—¶é—´çº¿æ ¼å¼"""
        return [
            {
                "step": s.step_name,
                "agent": s.agent_name,
                "action": s.action,
                "input": s.input_summary,
                "output": s.output_summary,
                "decisions": s.decision_points,
                "data": s.data_accessed,
                "time_ms": s.elapsed_ms,
                "tokens": s.tokens_used,
            }
            for s in self.steps
        ]


# ============================================================
# Output Attributor â€” è¾“å‡ºå½’å› 
# ============================================================

class OutputAttributor:
    """
    è¾“å‡ºå½’å›  â€” è§£é‡Šæ¯ä¸ªç»“è®ºçš„æ¥æº

    å°† Agent è¾“å‡ºæ‹†åˆ†ä¸ºå…·ä½“æ–­è¨€ï¼Œ
    æ¯ä¸ªæ–­è¨€è¿½æº¯åˆ°: æ•°æ®æ¥æºã€æ¨ç†é“¾ã€ä½¿ç”¨çš„è®°å¿†
    """

    def attribute(self, final_output: str,
                  expert_outputs: Dict[str, str] = None,
                  data_sources: List[str] = None,
                  memories_used: List[Dict] = None) -> List[OutputAttribution]:
        """ç”Ÿæˆè¾“å‡ºå½’å› """
        attributions = []

        # å°†è¾“å‡ºæ‹†åˆ†ä¸ºæ–­è¨€ (æŒ‰å¥å·/æ¢è¡Œ)
        claims = self._split_claims(final_output)

        for claim in claims[:10]:  # æœ€å¤š10ä¸ª
            attr = OutputAttribution(
                claim=claim,
                confidence=self._estimate_confidence(claim),
                supporting_data=self._find_data_support(claim, data_sources),
                source_agents=self._find_agent_sources(claim, expert_outputs),
                memory_used=[m["id"] for m in (memories_used or [])
                             if self._content_overlap(claim, m.get("content", ""))],
                reasoning_chain=self._infer_reasoning_chain(claim, expert_outputs),
            )
            attributions.append(attr)

        return attributions

    def _split_claims(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬æ‹†åˆ†ä¸ºç‹¬ç«‹æ–­è¨€"""
        import re
        # æŒ‰å¥å·ã€æ¢è¡Œã€åˆ†å·æ‹†åˆ†
        parts = re.split(r'[ã€‚\nï¼›;]', text)
        claims = [p.strip() for p in parts if len(p.strip()) > 10]
        return claims

    def _estimate_confidence(self, claim: str) -> float:
        """ä¼°ç®—æ–­è¨€ç½®ä¿¡åº¦"""
        score = 0.5

        # åŒ…å«å…·ä½“æ•°å­— â†’ æ›´é«˜ç½®ä¿¡
        import re
        if re.search(r'\d+[%ä¸‡äº¿]', claim):
            score += 0.2
        if re.search(r'\d+\.\d+', claim):
            score += 0.1

        # åŒ…å«é™å®šè¯ â†’ ç¨ä½ç½®ä¿¡
        hedges = ["å¯èƒ½", "ä¹Ÿè®¸", "å¤§çº¦", "ä¼°è®¡", "æ¨æµ‹"]
        if any(h in claim for h in hedges):
            score -= 0.1

        # åŒ…å«å¯¹æ¯”/å› æœ â†’ ä¸­ç­‰ç½®ä¿¡
        if any(kw in claim for kw in ["å› æ­¤", "æ‰€ä»¥", "å¯¼è‡´", "å› ä¸º"]):
            score += 0.1

        return max(0.1, min(1.0, score))

    def _find_data_support(self, claim: str,
                           data_sources: List[str] = None) -> List[Dict]:
        """æ‰¾å‡ºæ”¯æ’‘æ•°æ®"""
        supports = []
        if not data_sources:
            return supports

        for ds in data_sources[:5]:
            overlap = self._content_overlap(claim, ds)
            if overlap > 0.2:
                supports.append({
                    "source": ds[:50],
                    "overlap": round(overlap, 2),
                })
        return supports

    def _find_agent_sources(self, claim: str,
                            expert_outputs: Dict[str, str] = None) -> List[str]:
        """æ‰¾å‡ºè´¡çŒ®çš„ Agent"""
        if not expert_outputs:
            return []
        sources = []
        for agent, output in expert_outputs.items():
            if self._content_overlap(claim, output) > 0.15:
                sources.append(agent)
        return sources

    def _infer_reasoning_chain(self, claim: str,
                               expert_outputs: Dict[str, str] = None) -> str:
        """æ¨æ–­æ¨ç†é“¾"""
        if not expert_outputs:
            return "ç›´æ¥æ•°æ®æŸ¥è¯¢"

        chain_parts = []
        for agent, output in expert_outputs.items():
            if self._content_overlap(claim, output) > 0.1:
                chain_parts.append(agent)

        if chain_parts:
            return " â†’ ".join(chain_parts) + " â†’ ç»¼åˆç»“è®º"
        return "ç»¼åˆæ¨ç†"

    @staticmethod
    def _content_overlap(t1: str, t2: str) -> float:
        """æ–‡æœ¬é‡å åº¦"""
        s1 = set(t1.lower().split())
        s2 = set(t2.lower().split())
        if not s1 or not s2:
            return 0.0
        return len(s1 & s2) / max(len(s1 | s2), 1)


# ============================================================
# ç»Ÿä¸€è§£é‡Šå¼•æ“
# ============================================================

class InterpretabilityEngine:
    """
    MRARFAI å¯è§£é‡Šæ€§å¼•æ“ â€” ç»Ÿä¸€å…¥å£

    ç”¨æ³•:
        engine = InterpretabilityEngine()
        
        # å¼€å§‹è¿½è¸ª
        engine.start_trace(question)
        
        # å„é˜¶æ®µè¿½è¸ª
        engine.explain_intent(question, gate_result)
        engine.trace_gate(...)
        engine.trace_agent(...)
        engine.trace_memory(...)
        
        # ç”Ÿæˆå®Œæ•´è§£é‡Š
        explanation = engine.finalize(final_output, expert_outputs)
    """

    def __init__(self):
        self.intent_mapper = IntentMapper()
        self.tracer = ProcessTracer()
        self.attributor = OutputAttributor()
        self._query = ""
        self._intent = None
        self._start = 0

    def start_trace(self, query: str):
        """å¼€å§‹æ–°çš„è§£é‡Šè¿½è¸ª"""
        self._query = query
        self._start = time.time()
        self.tracer = ProcessTracer()
        self._intent = None

    def explain_intent(self, query: str,
                       gate_result: Dict = None) -> IntentExplanation:
        """è§£é‡Šæ„å›¾è¯†åˆ«"""
        self._intent = self.intent_mapper.explain_intent(query, gate_result)
        return self._intent

    def trace_gate(self, query: str, level: str,
                   score: float, agents: List[str]):
        self.tracer.trace_gate_decision(query, level, score, agents)

    def trace_agent(self, agent_name: str, question: str,
                    output_preview: str, elapsed_ms: float = 0,
                    tokens: int = 0, template: str = ""):
        self.tracer.trace_agent_call(
            agent_name, question, output_preview,
            elapsed_ms, tokens, template
        )

    def trace_memory(self, agent: str, query: str,
                     found: int, skills: int):
        self.tracer.trace_memory_recall(agent, query, found, skills)

    def trace_search(self, strategy: str, branches: int,
                     best_score: float, calls: int):
        self.tracer.trace_search(strategy, branches, best_score, calls)

    def finalize(self, final_output: str,
                 expert_outputs: Dict[str, str] = None,
                 data_sources: List[str] = None,
                 memories_used: List[Dict] = None) -> FullExplanation:
        """ç”Ÿæˆå®Œæ•´è§£é‡ŠæŠ¥å‘Š"""
        elapsed = (time.time() - self._start) * 1000

        # å½’å› 
        attributions = self.attributor.attribute(
            final_output, expert_outputs, data_sources, memories_used
        )

        # æ€»token
        total_tokens = sum(s.tokens_used for s in self.tracer.steps)

        # ä¸­æ–‡æ€»ç»“
        summary = self._generate_summary(
            self._intent, self.tracer.steps, attributions
        )

        return FullExplanation(
            query=self._query,
            intent=self._intent or self.intent_mapper.explain_intent(self._query),
            process=self.tracer.steps,
            attributions=attributions,
            summary_zh=summary,
            total_elapsed_ms=elapsed,
            total_tokens=total_tokens,
        )

    def _generate_summary(self, intent, steps, attributions) -> str:
        """ç”Ÿæˆä¸­æ–‡è§£é‡Šæ€»ç»“"""
        parts = []

        if intent:
            parts.append(f"è¯†åˆ«æ„å›¾: {intent.detected_intent} (ç½®ä¿¡åº¦{intent.confidence:.0%})")
            parts.append(f"è·¯ç”±å†³ç­–: {intent.route_decision} â€” {intent.route_reason}")

        if steps:
            agents_used = list(set(s.agent_name for s in steps))
            parts.append(f"æ‰§è¡Œäº† {len(steps)} ä¸ªæ­¥éª¤ï¼Œæ¶‰åŠ {', '.join(agents_used)}")

        if attributions:
            high_conf = [a for a in attributions if a.confidence > 0.7]
            parts.append(f"è¾“å‡ºåŒ…å« {len(attributions)} ä¸ªæ–­è¨€ï¼Œå…¶ä¸­ {len(high_conf)} ä¸ªé«˜ç½®ä¿¡")

        return " â†’ ".join(parts) if parts else "æ— è§£é‡Šä¿¡æ¯"

    def to_dict(self) -> Dict:
        """å¯¼å‡ºä¸º JSON å…¼å®¹å­—å…¸"""
        exp = self.finalize("", {})
        return {
            "query": exp.query,
            "intent": {
                "detected": exp.intent.detected_intent,
                "confidence": exp.intent.confidence,
                "route": exp.intent.route_decision,
                "reason": exp.intent.route_reason,
            },
            "process": self.tracer.to_timeline(),
            "summary": exp.summary_zh,
        }


# ============================================================
# å…¥å£
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("MRARFAI LatentLens Interpretability v9.0 Demo")
    print("=" * 60)

    engine = InterpretabilityEngine()

    # æ¨¡æ‹Ÿå®Œæ•´åˆ†ææµç¨‹
    query = "åˆ†æ2025å¹´å„å“ç‰Œå‡ºè´§è¶‹åŠ¿ï¼Œæ‰¾å‡ºå¼‚å¸¸å¹¶ç»™å‡ºå»ºè®®"
    print(f"\né—®é¢˜: {query}")

    engine.start_trace(query)

    # 1. æ„å›¾
    intent = engine.explain_intent(query, {"level": "full", "score": 0.82})
    print(f"\n--- æ„å›¾è§£é‡Š ---")
    print(f"  ä¸»æ„å›¾: {intent.detected_intent} ({intent.confidence:.0%})")
    print(f"  ä¿¡å·: {intent.intent_signals}")
    print(f"  è·¯ç”±: {intent.route_decision} â€” {intent.route_reason}")
    print(f"  å¤‡é€‰: {[a['intent'] for a in intent.alternative_intents]}")

    # 2. é—¨æ§
    engine.trace_gate(query, "full", 0.82, ["analyst", "risk", "strategist", "reporter"])

    # 3. è®°å¿†
    engine.trace_memory("analyst", query, found=3, skills=1)

    # 4. Agent è°ƒç”¨
    engine.trace_agent("analyst", query, "HMDå¢é•¿35%ï¼ŒTranssionç¨³å®š...",
                       elapsed_ms=1200, tokens=800, template="analyst-deep")
    engine.trace_agent("risk", query, "Top2é›†ä¸­åº¦55%ï¼Œå­˜åœ¨é£é™©...",
                       elapsed_ms=900, tokens=600, template="risk-standard")
    engine.trace_agent("strategist", query, "å»ºè®®æ‹“å±•å¹³æ¿å’Œæ–°å“ç‰Œ...",
                       elapsed_ms=1100, tokens=700, template="strategist-standard")

    # 5. æœç´¢
    engine.trace_search("two_level_beam", branches=9, best_score=0.87, calls=12)

    # 6. æœ€ç»ˆè§£é‡Š
    explanation = engine.finalize(
        final_output="2025å¹´å‡ºè´§è¶‹åŠ¿å‘ˆç°åˆ†åŒ–æ ¼å±€ã€‚HMDåŒæ¯”å¢é•¿35%é¢†è·‘ï¼ŒTranssionç¨³å®šåœ¨3.2äº¿ã€‚ä½†Top2é›†ä¸­åº¦è¾¾55%å­˜åœ¨é£é™©ã€‚å»ºè®®æ‹“å±•3-5ä¸ªæ–°å“ç‰Œã€‚",
        expert_outputs={
            "analyst": "HMDå¢é•¿35%ï¼ŒTranssion 3.2äº¿è¥æ”¶",
            "risk": "Top2é›†ä¸­åº¦55%ï¼Œå»ºè®®åˆ†æ•£",
            "strategist": "æ‹“å±•å¹³æ¿èµ›é“ï¼Œå¼€å‘æ–°å“ç‰Œ",
        },
    )

    print(f"\n--- æ¨ç†è¿‡ç¨‹ ({len(explanation.process)} æ­¥) ---")
    for step in explanation.process:
        print(f"  [{step.agent_name}] {step.step_name}: {step.action}")
        if step.output_summary:
            print(f"    â†’ {step.output_summary[:80]}")

    print(f"\n--- è¾“å‡ºå½’å›  ({len(explanation.attributions)} ä¸ªæ–­è¨€) ---")
    for attr in explanation.attributions:
        print(f"  ğŸ“ {attr.claim[:60]}")
        print(f"     ç½®ä¿¡: {attr.confidence:.0%} | æ¥æº: {attr.source_agents} | é“¾: {attr.reasoning_chain}")

    print(f"\n--- æ€»ç»“ ---")
    print(f"  {explanation.summary_zh}")
    print(f"  è€—æ—¶: {explanation.total_elapsed_ms:.0f}ms")
    print(f"  Tokens: {explanation.total_tokens}")

    print("\nâœ… LatentLens Interpretability Layer åˆå§‹åŒ–æˆåŠŸ")
