#!/usr/bin/env python3
"""
MRARFAI V8.0 â€” Integration Layer (é›†æˆå±‚)
============================================
å°† Phase I-IV å…¨éƒ¨é›†æˆåˆ°ç°æœ‰ multi_agent.py æµç¨‹ä¸­ã€‚

V7 â†’ V8 æµç¨‹å¯¹æ¯”:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
V7.0 æµç¨‹:                      V8.0 æµç¨‹:
1. ç¼“å­˜æ£€æŸ¥                      0. è¯­ä¹‰ç¼“å­˜æ£€æŸ¥ (Phase II)
2. æŒä¹…è®°å¿†åŠ è½½                   1. è‡ªé€‚åº”é—¨æ§è¯„ä¼° (Phase I)
3. SmartDataQuery                 2. ä¸Šä¸‹æ–‡å·¥ç¨‹ç¼–è¯‘ (Phase II)
4. SmartRouter (2çº§)              3. åŠ¨æ€Agentå·¥å‚ (Phase I)
5. ParallelAgentExecutor          4. å¹¶è¡Œæ‰§è¡Œ + åˆçº¦éªŒè¯ (Phase I)
6. Reporter                       5. ä¸Šä¸‹æ–‡å‹ç¼©ä¼ é€’ (Phase II)
7. CriticAgent                    6. ç»“æ„åŒ–Reviewerç¡¬é—¨æ§ (Phase IV)
8. HITL                           7. æŠ€èƒ½è’¸é¦ + è‡ªåŠ¨è¯„ä¼° (Phase IV)
9. æŒä¹…è®°å¿†ä¿å­˜                   8. å¤šç»´è®°å¿†å›¾æ›´æ–° (Phase III)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

å‘åå…¼å®¹: æ‰€æœ‰ V7 æ¥å£ä¿æŒä¸å˜ï¼ŒV8 æ¨¡å— try/except å¯¼å…¥
"""

import json
import time
from typing import Dict, List, Optional, Any

# ============================================================
# V8.0 æ¨¡å—å¯¼å…¥ (å…¨éƒ¨ try/except ä¿è¯å‘åå…¼å®¹)
# ============================================================

# Phase I: è‡ªé€‚åº”é—¨æ§
try:
    from adaptive_gate import (
        AdaptiveGate, AgentFactory, ContractValidator,
        get_gate, get_factory, get_validator,
        adaptive_route, ComplexityLevel, ComplexityAssessment,
    )
    HAS_V8_GATE = True
except ImportError:
    HAS_V8_GATE = False

# Phase II: ä¸Šä¸‹æ–‡å·¥ç¨‹
try:
    from context_engine import (
        ContextCompressor, SemanticCache, WorkingContextBuilder,
        EvolvingPlaybook, YAMLContextSchema,
        get_context_cache, get_playbook,
        build_working_context, compress_agent_output,
    )
    HAS_V8_CTX = True
except ImportError:
    HAS_V8_CTX = False

# Phase III: å…ƒè®°å¿†
try:
    from meta_memory import (
        MemoryGraph, TELOSProfile, MemoryType, MemoryNode,
        get_memory_graph, set_memory_graph,
    )
    HAS_V8_MEM = True
except ImportError:
    HAS_V8_MEM = False

# Phase IV: è‡ªè¿›åŒ–
try:
    from self_evolution import (
        StructuredReviewer, AutoEvalLoop, SkillDistiller,
        get_reviewer, get_eval_loop, get_distiller,
    )
    HAS_V8_EVO = True
except ImportError:
    HAS_V8_EVO = False


# ============================================================
# V8.0 èƒ½åŠ›æ‘˜è¦
# ============================================================

def get_v8_capabilities() -> Dict[str, Any]:
    """è·å– V8.0 å„æ¨¡å—å¯ç”¨çŠ¶æ€"""
    return {
        "v8_available": any([HAS_V8_GATE, HAS_V8_CTX, HAS_V8_MEM, HAS_V8_EVO]),
        "phase_i_gate": HAS_V8_GATE,
        "phase_ii_context": HAS_V8_CTX,
        "phase_iii_memory": HAS_V8_MEM,
        "phase_iv_evolution": HAS_V8_EVO,
        "modules": {
            "adaptive_gate": "âœ…" if HAS_V8_GATE else "âŒ",
            "context_engine": "âœ…" if HAS_V8_CTX else "âŒ",
            "meta_memory": "âœ…" if HAS_V8_MEM else "âŒ",
            "self_evolution": "âœ…" if HAS_V8_EVO else "âŒ",
        },
    }


# ============================================================
# V8.0 å¢å¼ºæµç¨‹èŠ‚ç‚¹ â€” æ’å…¥åˆ°ç°æœ‰ Pipeline ä¸­
# ============================================================

class V8Pipeline:
    """
    V8.0 å¢å¼º Pipeline

    ä¸æ›¿æ¢ V7 çš„ ask_multi_agentï¼Œè€Œæ˜¯åŒ…è£…å¢å¼º:
    - åœ¨å…³é”®èŠ‚ç‚¹æ’å…¥ V8 å¤„ç†
    - V8 æ¨¡å—ä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§åˆ° V7 é€»è¾‘
    """

    def __init__(self):
        self.thinking: List[str] = []
        self.v8_stats: Dict[str, Any] = {}

    # ---- Phase I: é—¨æ§è·¯ç”± ----

    def adaptive_route(self, question: str, context: dict = None,
                       provider: str = "deepseek") -> Dict:
        """
        V8 è‡ªé€‚åº”è·¯ç”± (æ›¿ä»£ SmartRouter)

        Returns:
            {
                "level": "skip|light|full",
                "agents": [...],
                "score": float,
                "reason": str,
                "v8_active": bool,
            }
        """
        if not HAS_V8_GATE:
            return {"level": "full", "agents": [], "v8_active": False}

        gate = get_gate()
        assessment = gate.route(question, context)

        self.thinking.append(
            f"ğŸ”€ V8é—¨æ§: {assessment.level.value} "
            f"(score={assessment.score:.2f}) â†’ "
            f"{assessment.reason}"
        )
        self.v8_stats["gate"] = {
            "level": assessment.level.value,
            "score": assessment.score,
            "agents": assessment.agents_recommended,
        }

        return {
            "level": assessment.level.value,
            "agents": assessment.agents_recommended,
            "score": assessment.score,
            "reason": assessment.reason,
            "v8_active": True,
            "assessment": assessment,
        }

    # ---- Phase II: ä¸Šä¸‹æ–‡ç¼–è¯‘ ----

    def compile_context(self, question: str, data: dict, results: dict,
                        memory_context: str = "",
                        level: str = "full",
                        agent_id: str = "") -> str:
        """
        V8 ä¸Šä¸‹æ–‡ç¼–è¯‘ (æ›¿ä»£ç®€å•æ‹¼æ¥)
        """
        if not HAS_V8_CTX:
            return ""

        ctx = build_working_context(
            question, data, results, memory_context, level, agent_id
        )

        self.thinking.append(
            f"ğŸ“‹ V8ä¸Šä¸‹æ–‡: {len(ctx)}å­— (level={level})"
        )
        return ctx

    def check_semantic_cache(self, question: str) -> Optional[Dict]:
        """V8 è¯­ä¹‰ç¼“å­˜æ£€æŸ¥"""
        if not HAS_V8_CTX:
            return None

        cache = get_context_cache()
        result = cache.get(question)
        if result:
            self.thinking.append("âš¡ V8è¯­ä¹‰ç¼“å­˜å‘½ä¸­")
        return result

    def save_to_semantic_cache(self, question: str, result: dict):
        """ä¿å­˜åˆ°è¯­ä¹‰ç¼“å­˜"""
        if HAS_V8_CTX:
            cache = get_context_cache()
            cache.put(question, result)

    def compress_output(self, output: str, strategy: str = "moderate") -> str:
        """V8 Agent è¾“å‡ºå‹ç¼©"""
        if not HAS_V8_CTX:
            return output
        return compress_agent_output(output, strategy)

    # ---- Phase I: åˆçº¦éªŒè¯ ----

    def validate_output(self, agent_id: str, output: str) -> Dict:
        """V8 Agent è¾“å‡ºåˆçº¦éªŒè¯"""
        if not HAS_V8_GATE:
            return {"valid": True, "issues": []}

        validator = get_validator()
        is_valid, issues = validator.validate(agent_id, output)

        if not is_valid:
            self.thinking.append(
                f"âš ï¸ åˆçº¦è¿å [{agent_id}]: {'; '.join(issues)}"
            )

        return {"valid": is_valid, "issues": issues}

    # ---- Phase III: å…ƒè®°å¿† ----

    def load_memory_context(self, question: str,
                            entities: List[str] = None) -> str:
        """V8 å…ƒè®°å¿†ä¸Šä¸‹æ–‡åŠ è½½"""
        if not HAS_V8_MEM:
            return ""

        graph = get_memory_graph()
        ctx = graph.build_memory_context(question, entities)

        if ctx:
            self.thinking.append(f"ğŸ§  V8å…ƒè®°å¿†: åŠ è½½ {len(ctx)} å­—ä¸Šä¸‹æ–‡")
        return ctx

    def save_to_memory(self, question: str, answer: str,
                       agents_used: List[str],
                       entities: List[str] = None,
                       importance: float = 0.5):
        """V8 ä¿å­˜åˆ°è®°å¿†å›¾"""
        if not HAS_V8_MEM:
            return

        graph = get_memory_graph()
        graph.add(
            content=f"Q: {question[:100]} â†’ A: {answer[:200]}",
            memory_type=MemoryType.EPISODIC,
            importance=importance,
            entities=entities or [],
            tags=agents_used,
            source="analysis",
        )

    def build_telos_profiles(self, customer_data: list,
                             health_scores: list = None):
        """æ‰¹é‡æ„å»º TELOS ç”»åƒ"""
        if not HAS_V8_MEM:
            return

        graph = get_memory_graph()
        for customer in customer_data[:50]:  # Top 50 å®¢æˆ·
            graph.build_telos_from_data(customer, health_scores)

    # ---- Phase IV: è‡ªè¿›åŒ– ----

    def review_answer(self, answer: str, question: str,
                      context: str = "",
                      expert_outputs: Dict[str, str] = None) -> Dict:
        """V8 ç»“æ„åŒ–å®¡æŸ¥"""
        if not HAS_V8_EVO:
            return {"passed": True, "score": 7.0}

        reviewer = get_reviewer()
        result = reviewer.review(answer, question, context, expert_outputs)

        self.thinking.append(
            f"ğŸ“ V8å®¡æŸ¥: {result.overall_score:.1f}/10 "
            f"({'âœ…' if result.passed else 'âŒ'}) "
            f"è€—æ—¶{result.review_time_ms:.0f}ms"
        )
        if result.blockers:
            for b in result.blockers:
                self.thinking.append(f"  ğŸš« {b}")

        self.v8_stats["review"] = result.to_dict()
        return result.to_dict()

    def auto_evaluate(self, answer: str, question: str,
                      context: str = "",
                      metadata: Dict = None) -> Dict:
        """V8 è‡ªåŠ¨è¯„ä¼°"""
        if not HAS_V8_EVO:
            return {}

        loop = get_eval_loop()
        result = loop.evaluate(answer, question, context, metadata=metadata)

        if result.get("alert"):
            self.thinking.append(f"ğŸš¨ {result['alert']}")

        self.v8_stats["eval"] = {
            "trend": result.get("trend"),
            "avg": result.get("avg_score"),
            "count": result.get("eval_count"),
        }
        return result

    def match_skills(self, question: str) -> List[Dict]:
        """V8 æŠ€èƒ½åŒ¹é…"""
        if not HAS_V8_EVO:
            return []

        distiller = get_distiller()
        skills = distiller.match_skills(question)

        if skills:
            self.thinking.append(
                f"ğŸ¯ V8æŠ€èƒ½: åŒ¹é… {len(skills)} ä¸ª "
                f"({', '.join(s.name for s in skills)})"
            )
        return [{"name": s.name, "strategy": s.strategy} for s in skills]

    def record_trajectory(self, question: str, answer: str,
                          agents_used: List[str], score: float,
                          expert_outputs: Dict = None):
        """V8 è®°å½•åˆ†æè½¨è¿¹"""
        if not HAS_V8_EVO:
            return

        distiller = get_distiller()
        distiller.record_trajectory(
            question, answer, agents_used, score, expert_outputs
        )

    # ---- ç»¼åˆç»Ÿè®¡ ----

    def get_stats(self) -> Dict:
        """V8 å…¨å±€ç»Ÿè®¡"""
        stats = {
            "capabilities": get_v8_capabilities(),
            "v8_stats": self.v8_stats,
        }

        if HAS_V8_GATE:
            stats["gate_stats"] = get_gate().get_stats()
        if HAS_V8_CTX:
            stats["cache_stats"] = get_context_cache().get_stats()
            stats["playbook_stats"] = get_playbook().get_all_stats()
        if HAS_V8_MEM:
            stats["memory_stats"] = get_memory_graph().get_stats()
        if HAS_V8_EVO:
            stats["eval_report"] = get_eval_loop().get_report()
            stats["skill_stats"] = get_distiller().get_stats()

        return stats


# ============================================================
# V8 å¢å¼ºç‰ˆ ask_multi_agent â€” åŒ…è£…å™¨
# ============================================================

def ask_multi_agent_v8(
    question: str,
    data: dict,
    results: dict,
    benchmark: dict = None,
    forecast: dict = None,
    provider: str = "deepseek",
    api_key: str = "",
    memory=None,
    # V7 å‚æ•°
    enable_critic: bool = True,
    enable_hitl_v2: bool = True,
    enable_persistent_mem: bool = True,
    critic_threshold: float = 7.0,
    critic_max_iter: int = 2,
    stream_callback=None,
    enable_tools: bool = True,
    enable_cache: bool = True,
    # V8 æ–°å¢å‚æ•°
    enable_v8: bool = True,         # V8 æ€»å¼€å…³
    enable_gate: bool = True,       # Phase I
    enable_context_eng: bool = True, # Phase II
    enable_meta_memory: bool = True, # Phase III
    enable_evolution: bool = True,   # Phase IV
    force_level: str = None,        # å¼ºåˆ¶é—¨æ§çº§åˆ« (è°ƒè¯•)
) -> dict:
    """
    V8.0 ä¸»å…¥å£ â€” å¢å¼ºç‰ˆ ask_multi_agent

    å‘åå…¼å®¹ V7 æ‰€æœ‰å‚æ•°ï¼Œæ–°å¢ V8 å¼€å…³ã€‚
    V8 æ¨¡å—ä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§åˆ° V7ã€‚
    """
    # å¦‚æœä¸å¯ç”¨ V8ï¼Œç›´æ¥èµ° V7
    if not enable_v8:
        from multi_agent import ask_multi_agent
        return ask_multi_agent(
            question, data, results, benchmark, forecast,
            provider, api_key, memory,
            enable_critic=enable_critic,
            enable_hitl_v2=enable_hitl_v2,
            enable_persistent_mem=enable_persistent_mem,
            critic_threshold=critic_threshold,
            critic_max_iter=critic_max_iter,
            stream_callback=stream_callback,
            enable_tools=enable_tools,
            enable_cache=enable_cache,
        )

    t0 = time.time()
    v8 = V8Pipeline()
    v8.thinking.append(f"ğŸ“© V8.0 æ”¶åˆ°: {question}")
    v8.thinking.append(f"ğŸ”§ V8æ¨¡å—: {get_v8_capabilities()['modules']}")

    # ---- Step 0: è¯­ä¹‰ç¼“å­˜ (Phase II) ----
    if enable_context_eng:
        cached = v8.check_semantic_cache(question)
        if cached:
            cached["from_cache"] = True
            cached["v8_enhanced"] = True
            return cached

    # ---- Step 1: è‡ªé€‚åº”é—¨æ§ (Phase I) ----
    gate_result = {"level": "full", "agents": []}
    if enable_gate:
        gate_result = v8.adaptive_route(question, provider=provider)

    level = gate_result.get("level", "full")

    # ---- Step 2: å…ƒè®°å¿†åŠ è½½ (Phase III) ----
    v8_memory_ctx = ""
    if enable_meta_memory:
        # æå–é—®é¢˜ä¸­å¯èƒ½çš„å®ä½“
        entities = _extract_entities_simple(question, data)
        v8_memory_ctx = v8.load_memory_context(question, entities)

    # ---- Step 3: æŠ€èƒ½åŒ¹é… (Phase IV) ----
    matched_skills = []
    if enable_evolution:
        matched_skills = v8.match_skills(question)

    # ---- Step 4: è°ƒç”¨ V7 æ ¸å¿ƒæµç¨‹ (å¸¦ V8 å¢å¼ºå‚æ•°) ----
    from multi_agent import ask_multi_agent
    v7_result = ask_multi_agent(
        question, data, results, benchmark, forecast,
        provider, api_key, memory,
        enable_critic=enable_critic,
        enable_hitl_v2=enable_hitl_v2,
        enable_persistent_mem=enable_persistent_mem,
        critic_threshold=critic_threshold,
        critic_max_iter=critic_max_iter,
        stream_callback=stream_callback,
        enable_tools=enable_tools,
        enable_cache=enable_cache,
    )

    # ---- Step 5: V8 åå¤„ç† ----
    answer = v7_result.get("answer", "")
    expert_outputs = v7_result.get("expert_outputs", {})
    agents_used = v7_result.get("agents_used", [])

    # Phase I: åˆçº¦éªŒè¯
    if enable_gate:
        for agent_id, output in expert_outputs.items():
            # æå– agent_id (å»æ‰ emoji)
            clean_id = "analyst" if "åˆ†æ" in agent_id else (
                "risk" if "é£æ§" in agent_id else (
                "strategist" if "ç­–ç•¥" in agent_id else ""
            ))
            if clean_id:
                v8.validate_output(clean_id, output)

    # Phase IV: ç»“æ„åŒ–å®¡æŸ¥
    review_result = {}
    if enable_evolution:
        review_result = v8.review_answer(
            answer, question,
            context=json.dumps(results, ensure_ascii=False, default=str)[:3000],
            expert_outputs=expert_outputs,
        )

    # Phase IV: è‡ªåŠ¨è¯„ä¼°
    eval_result = {}
    if enable_evolution:
        eval_result = v8.auto_evaluate(answer, question, metadata={
            "agents": agents_used,
            "gate_level": level,
        })

    # Phase IV: è½¨è¿¹è®°å½• + æŠ€èƒ½è’¸é¦
    if enable_evolution:
        score = review_result.get("score", 7.0)
        v8.record_trajectory(question, answer, agents_used, score, expert_outputs)

    # Phase III: è®°å¿†ä¿å­˜
    if enable_meta_memory:
        entities = _extract_entities_simple(question, data)
        v8.save_to_memory(
            question, answer, agents_used,
            entities=entities,
            importance=min(review_result.get("score", 5.0) / 10, 1.0),
        )

    # Phase II: è¯­ä¹‰ç¼“å­˜ä¿å­˜
    if enable_context_eng:
        v8.save_to_semantic_cache(question, v7_result)

    elapsed = time.time() - t0
    v8.thinking.append(f"â±ï¸ V8æ€»è€—æ—¶ {elapsed:.1f}ç§’")

    # ---- åˆå¹¶ç»“æœ ----
    v7_result["v8_enhanced"] = True
    v7_result["v8_thinking"] = v8.thinking
    v7_result["v8_stats"] = v8.get_stats()
    v7_result["v8_gate_level"] = level
    v7_result["v8_review"] = review_result
    v7_result["v8_eval"] = eval_result
    v7_result["v8_skills_matched"] = matched_skills

    # åˆå¹¶ thinking
    original_thinking = v7_result.get("thinking", [])
    v7_result["thinking"] = v8.thinking + original_thinking

    return v7_result


def _extract_entities_simple(question: str, data: dict) -> List[str]:
    """ç®€å•å®ä½“æå–"""
    entities = []
    customers = data.get('å®¢æˆ·é‡‘é¢', [])
    if isinstance(customers, list):
        for c in customers[:50]:
            name = c.get('å®¢æˆ·', '')
            if name and len(name) >= 2 and name in question:
                entities.append(name)
    return entities[:10]


# ============================================================
# å…¨å±€ V8 Pipeline å®ä¾‹
# ============================================================

_v8_pipeline: Optional[V8Pipeline] = None

def get_v8_pipeline() -> V8Pipeline:
    global _v8_pipeline
    if _v8_pipeline is None:
        _v8_pipeline = V8Pipeline()
    return _v8_pipeline
