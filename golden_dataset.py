#!/usr/bin/env python3
"""
MRARFAI Golden Dataset v5.0
===============================
Phase 1 å‡çº§ï¼šå»ºç«‹è´¨é‡å›å½’æµ‹è¯•åŸºå‡†

åŠŸèƒ½ï¼š
  â‘  ç®¡ç†ã€Œé—®é¢˜ + æ ‡å‡†ç­”æ¡ˆ + æ ‡ç­¾ã€æµ‹è¯•é›†
  â‘¡ å¯¹æ¥ Langfuse Dataset APIï¼ˆå¯é€‰ï¼‰
  â‘¢ è¿è¡Œå›å½’æµ‹è¯• + LLM-as-Judge è‡ªåŠ¨è¯„åˆ†
  â‘£ ç‰ˆæœ¬å¯¹æ¯”ï¼ˆv4.3 vs v5.0 è´¨é‡å·®å¼‚ï¼‰

å­˜å‚¨ï¼šSQLite æœ¬åœ° + Langfuse äº‘ç«¯ï¼ˆå¯é€‰åŒå†™ï¼‰
"""

import json
import sqlite3
import time
import os
import logging
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Callable, Any

logger = logging.getLogger("mrarfai.golden")


# ============================================================
# æ•°æ®æ¨¡å‹
# ============================================================

@dataclass
class GoldenCase:
    """ä¸€æ¡é»„é‡‘æµ‹è¯•ç”¨ä¾‹"""
    case_id: str                      # å”¯ä¸€ID: "GC-001"
    question: str                     # ç”¨æˆ·é—®é¢˜
    expected_keywords: List[str]      # ç­”æ¡ˆä¸­å¿…é¡»åŒ…å«çš„å…³é”®è¯
    expected_pattern: str = ""        # ç­”æ¡ˆçš„ç»“æ„æè¿°
    category: str = "general"         # åˆ†ç±»: general/risk/product/trend/region
    difficulty: str = "medium"        # easy/medium/hard
    context_hint: str = ""            # æç¤ºï¼šè¿™ä¸ªé—®é¢˜éœ€è¦ä»€ä¹ˆæ•°æ®
    created_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()


@dataclass
class RegressionResult:
    """å›å½’æµ‹è¯•ç»“æœ"""
    case_id: str
    question: str
    agent_output: str
    scores: Dict                      # LLM-as-Judge è¯„åˆ†
    keyword_hits: int                 # å…³é”®è¯å‘½ä¸­æ•°
    keyword_total: int                # å…³é”®è¯æ€»æ•°
    keyword_score: float              # å…³é”®è¯å‘½ä¸­ç‡
    overall_score: float              # ç»¼åˆåˆ†æ•°
    elapsed_ms: float = 0
    error: str = ""


@dataclass
class RegressionReport:
    """ä¸€æ¬¡å›å½’æµ‹è¯•çš„å®Œæ•´æŠ¥å‘Š"""
    version: str                      # ä»£ç ç‰ˆæœ¬æ ‡ç­¾
    timestamp: str
    total_cases: int
    results: List[RegressionResult]
    avg_scores: Dict[str, float]      # å„ç»´åº¦å¹³å‡åˆ†
    overall_avg: float
    keyword_avg: float
    elapsed_total_ms: float


# ============================================================
# å†…ç½®é»„é‡‘æµ‹è¯•é›† â€” è¦†ç›–æ ¸å¿ƒä¸šåŠ¡åœºæ™¯
# ============================================================

DEFAULT_GOLDEN_CASES = [
    # --- åŒºåŸŸåˆ†æ ---
    GoldenCase(
        case_id="GC-001",
        question="åä¸œåŒºä»Šå¹´æ•´ä½“è¡¨ç°å¦‚ä½•ï¼Ÿ",
        expected_keywords=["è¥æ”¶", "åŒæ¯”", "å¢é•¿", "å®¢æˆ·"],
        expected_pattern="åŒ…å«æ€»è¥æ”¶ã€å¢é•¿ç‡ã€ä¸»è¦å®¢æˆ·ã€è¶‹åŠ¿åˆ¤æ–­",
        category="region",
        difficulty="easy",
    ),
    GoldenCase(
        case_id="GC-002",
        question="å¯¹æ¯”å„åŒºåŸŸçš„é”€å”®è¡¨ç°ï¼Œå“ªä¸ªåŒºåŸŸå¢é•¿æœ€å¿«ï¼Ÿ",
        expected_keywords=["åŒºåŸŸ", "å¢é•¿", "å¯¹æ¯”", "æœ€å¿«"],
        expected_pattern="åŒ…å«å„åŒºåŸŸæ•°æ®å¯¹æ¯”ã€å¢é•¿ç‡æ’å",
        category="region",
        difficulty="medium",
    ),
    
    # --- å®¢æˆ·é£é™© ---
    GoldenCase(
        case_id="GC-010",
        question="å“ªäº›å®¢æˆ·æœ‰æµå¤±é£é™©ï¼Ÿç»™å‡ºå…·ä½“æ•°æ®æ”¯æ’‘",
        expected_keywords=["æµå¤±", "é£é™©", "ä¸‹é™", "å®¢æˆ·"],
        expected_pattern="åŒ…å«å…·ä½“å®¢æˆ·åã€ä¸‹é™å¹…åº¦ã€æœˆåº¦è¶‹åŠ¿ã€é£é™©ç­‰çº§",
        category="risk",
        difficulty="medium",
    ),
    GoldenCase(
        case_id="GC-011",
        question="å®¢æˆ·é›†ä¸­åº¦æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆé£é™©ï¼Ÿ",
        expected_keywords=["é›†ä¸­åº¦", "Top", "å æ¯”", "é£é™©"],
        expected_pattern="åŒ…å«Top3/Top5å æ¯”ã€HHIæŒ‡æ•°æˆ–ç±»ä¼¼æŒ‡æ ‡ã€å»ºè®®",
        category="risk",
        difficulty="medium",
    ),
    GoldenCase(
        case_id="GC-012",
        question="æœ€è¿‘ä¸‰ä¸ªæœˆé›¶å‡ºè´§çš„å®¢æˆ·æœ‰å“ªäº›ï¼Ÿ",
        expected_keywords=["é›¶å‡ºè´§", "å®¢æˆ·", "æœˆ"],
        expected_pattern="åŒ…å«å…·ä½“å®¢æˆ·åˆ—è¡¨ã€ä¹‹å‰çš„å‡ºè´§é‡å¯¹æ¯”",
        category="risk",
        difficulty="easy",
    ),
    
    # --- äº§å“åˆ†æ ---
    GoldenCase(
        case_id="GC-020",
        question="å„äº§å“çº¿çš„è¥æ”¶å æ¯”å’Œå¢é•¿è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
        expected_keywords=["äº§å“", "å æ¯”", "å¢é•¿", "è¶‹åŠ¿"],
        expected_pattern="åŒ…å«å„äº§å“çº¿é‡‘é¢ã€å æ¯”ã€åŒæ¯”å¢é•¿ç‡",
        category="product",
        difficulty="medium",
    ),
    GoldenCase(
        case_id="GC-021",
        question="å“ªäº›äº§å“æ˜¯æ˜æ˜Ÿäº§å“ï¼Ÿå“ªäº›åœ¨èç¼©ï¼Ÿ",
        expected_keywords=["æ˜æ˜Ÿ", "å¢é•¿", "èç¼©", "äº§å“"],
        expected_pattern="åŒ…å«BCGåˆ†ç±»æˆ–ç±»ä¼¼åˆ†æã€å…·ä½“äº§å“çº¿åç§°",
        category="product",
        difficulty="hard",
    ),
    
    # --- è¶‹åŠ¿é¢„æµ‹ ---
    GoldenCase(
        case_id="GC-030",
        question="ä»Šå¹´çš„æœˆåº¦å‡ºè´§è¶‹åŠ¿å¦‚ä½•ï¼Ÿæœ‰ä»€ä¹ˆè§„å¾‹ï¼Ÿ",
        expected_keywords=["æœˆåº¦", "è¶‹åŠ¿", "å³°", "è°·"],
        expected_pattern="åŒ…å«æœˆåº¦æ•°æ®èµ°åŠ¿ã€å³°å€¼æœˆä»½ã€å­£èŠ‚æ€§è§„å¾‹",
        category="trend",
        difficulty="medium",
    ),
    GoldenCase(
        case_id="GC-031",
        question="æŒ‰ç›®å‰è¶‹åŠ¿ï¼Œä¸‹ä¸ªå­£åº¦é¢„è®¡è¥æ”¶å¤šå°‘ï¼Ÿ",
        expected_keywords=["é¢„æµ‹", "å­£åº¦", "è¥æ”¶", "è¶‹åŠ¿"],
        expected_pattern="åŒ…å«é¢„æµ‹æ•°å­—ã€é¢„æµ‹æ–¹æ³•è¯´æ˜ã€ç½®ä¿¡åº¦",
        category="trend",
        difficulty="hard",
    ),
    
    # --- ç»¼åˆç­–ç•¥ ---
    GoldenCase(
        case_id="GC-040",
        question="ç»™æˆ‘ä¸€ä»½å¹´åº¦é”€å”®æ€»ç»“ï¼Œé‡ç‚¹æ˜¯é£é™©å’Œæœºä¼š",
        expected_keywords=["æ€»ç»“", "é£é™©", "æœºä¼š", "å»ºè®®"],
        expected_pattern="ç»“æ„åŒ–æŠ¥å‘Šï¼šä¸šç»©æ¦‚è§ˆã€å…³é”®é£é™©ã€å¢é•¿æœºä¼šã€è¡ŒåŠ¨å»ºè®®",
        category="general",
        difficulty="hard",
    ),
    GoldenCase(
        case_id="GC-041",
        question="å¦‚æœè¦æå‡æ˜å¹´è¥æ”¶20%ï¼Œä½ æœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ",
        expected_keywords=["å»ºè®®", "å¢é•¿", "ç­–ç•¥", "è¡ŒåŠ¨"],
        expected_pattern="åŒ…å«å…·ä½“ç­–ç•¥ã€æ•°æ®æ”¯æ’‘ã€ä¼˜å…ˆçº§æ’åº",
        category="general",
        difficulty="hard",
    ),
]


# ============================================================
# æ•°æ®é›†ç®¡ç†å™¨ï¼ˆSQLiteï¼‰
# ============================================================

class GoldenDatasetManager:
    """ç®¡ç†é»„é‡‘æµ‹è¯•é›†çš„å¢åˆ æ”¹æŸ¥å’ŒæŒä¹…åŒ–"""
    
    def __init__(self, db_path: str = "golden_dataset.db"):
        self.db_path = db_path
        self._conn = sqlite3.connect(db_path)
        self._init_db()
    
    def _get_conn(self):
        return self._conn
    
    def _init_db(self):
        conn = self._get_conn()
        with conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS golden_cases (
                    case_id TEXT PRIMARY KEY,
                    question TEXT NOT NULL,
                    expected_keywords TEXT,
                    expected_pattern TEXT,
                    category TEXT DEFAULT 'general',
                    difficulty TEXT DEFAULT 'medium',
                    context_hint TEXT,
                    created_at TEXT
                )
            """)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS regression_runs (
                    run_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    version TEXT,
                    timestamp TEXT,
                    total_cases INTEGER,
                    overall_avg REAL,
                    keyword_avg REAL,
                    scores_json TEXT,
                    elapsed_ms REAL
                )
            """)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS regression_details (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    run_id INTEGER,
                    case_id TEXT,
                    agent_output TEXT,
                    scores_json TEXT,
                    keyword_score REAL,
                    overall_score REAL,
                    error TEXT,
                    FOREIGN KEY (run_id) REFERENCES regression_runs(run_id)
                )
            """)
    
    def load_defaults(self):
        """åŠ è½½å†…ç½®æµ‹è¯•ç”¨ä¾‹ï¼ˆä¸è¦†ç›–å·²å­˜åœ¨çš„ï¼‰"""
        count = 0
        for case in DEFAULT_GOLDEN_CASES:
            if not self.get_case(case.case_id):
                self.add_case(case)
                count += 1
        return count
    
    def add_case(self, case: GoldenCase):
        """æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
        conn = self._get_conn()
        with conn:
            conn.execute("""
                INSERT OR REPLACE INTO golden_cases 
                (case_id, question, expected_keywords, expected_pattern,
                 category, difficulty, context_hint, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                case.case_id, case.question,
                json.dumps(case.expected_keywords, ensure_ascii=False),
                case.expected_pattern, case.category,
                case.difficulty, case.context_hint, case.created_at,
            ))
    
    def get_case(self, case_id: str) -> Optional[GoldenCase]:
        conn = self._get_conn()
        with conn:
            row = conn.execute(
                "SELECT * FROM golden_cases WHERE case_id = ?", (case_id,)
            ).fetchone()
            if row:
                return self._row_to_case(row)
        return None
    
    def list_cases(self, category: str = None) -> List[GoldenCase]:
        conn = self._get_conn()
        with conn:
            if category:
                rows = conn.execute(
                    "SELECT * FROM golden_cases WHERE category = ? ORDER BY case_id",
                    (category,),
                ).fetchall()
            else:
                rows = conn.execute(
                    "SELECT * FROM golden_cases ORDER BY case_id"
                ).fetchall()
        return [self._row_to_case(r) for r in rows]
    
    def count(self) -> int:
        conn = self._get_conn()
        with conn:
            return conn.execute("SELECT COUNT(*) FROM golden_cases").fetchone()[0]
    
    def delete_case(self, case_id: str):
        conn = self._get_conn()
        with conn:
            conn.execute("DELETE FROM golden_cases WHERE case_id = ?", (case_id,))
    
    def _row_to_case(self, row) -> GoldenCase:
        return GoldenCase(
            case_id=row[0],
            question=row[1],
            expected_keywords=json.loads(row[2]) if row[2] else [],
            expected_pattern=row[3] or "",
            category=row[4] or "general",
            difficulty=row[5] or "medium",
            context_hint=row[6] or "",
            created_at=row[7] or "",
        )
    
    # ---- å›å½’æµ‹è¯•è®°å½• ----
    
    def save_regression_run(self, report: RegressionReport) -> int:
        """ä¿å­˜ä¸€æ¬¡å›å½’æµ‹è¯•ç»“æœ"""
        conn = self._get_conn()
        with conn:
            cursor = conn.execute("""
                INSERT INTO regression_runs 
                (version, timestamp, total_cases, overall_avg, keyword_avg, scores_json, elapsed_ms)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                report.version, report.timestamp, report.total_cases,
                report.overall_avg, report.keyword_avg,
                json.dumps(report.avg_scores, ensure_ascii=False),
                report.elapsed_total_ms,
            ))
            run_id = cursor.lastrowid
            
            for r in report.results:
                conn.execute("""
                    INSERT INTO regression_details 
                    (run_id, case_id, agent_output, scores_json, keyword_score, overall_score, error)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    run_id, r.case_id, r.agent_output[:500],
                    json.dumps(r.scores, ensure_ascii=False),
                    r.keyword_score, r.overall_score, r.error,
                ))
            
            return run_id
    
    def get_regression_history(self, limit: int = 10) -> List[Dict]:
        """è·å–å†å²å›å½’æµ‹è¯•è®°å½•ï¼ˆç”¨äºç‰ˆæœ¬å¯¹æ¯”ï¼‰"""
        conn = self._get_conn()
        with conn:
            rows = conn.execute("""
                SELECT version, timestamp, total_cases, overall_avg, keyword_avg, scores_json, elapsed_ms
                FROM regression_runs
                ORDER BY run_id DESC
                LIMIT ?
            """, (limit,)).fetchall()
        
        return [{
            "version": r[0],
            "timestamp": r[1],
            "total_cases": r[2],
            "overall_avg": r[3],
            "keyword_avg": r[4],
            "avg_scores": json.loads(r[5]) if r[5] else {},
            "elapsed_ms": r[6],
        } for r in rows]


# ============================================================
# å›å½’æµ‹è¯•æ‰§è¡Œå™¨
# ============================================================

def run_regression(
    agent_fn: Callable,
    version_tag: str = "dev",
    categories: List[str] = None,
    provider: str = "claude",
    api_key: str = "",
    db_path: str = "golden_dataset.db",
    use_judge: bool = True,
) -> RegressionReport:
    """
    è¿è¡Œå®Œæ•´çš„å›å½’æµ‹è¯•
    
    å‚æ•°:
        agent_fn: Agent è°ƒç”¨å‡½æ•°ï¼Œç­¾å fn(question) -> str
        version_tag: ç‰ˆæœ¬æ ‡ç­¾ï¼Œå¦‚ "v4.3", "v5.0-langfuse"
        categories: åªæµ‹è¯•æŸäº›åˆ†ç±»ï¼ŒNone=å…¨éƒ¨
        provider: LLM-as-Judge ç”¨çš„ provider
        api_key: API Key
        db_path: æ•°æ®åº“è·¯å¾„
        use_judge: æ˜¯å¦ä½¿ç”¨ LLM-as-Judgeï¼ˆFalse æ—¶åªåšå…³é”®è¯åŒ¹é…ï¼‰
    
    è¿”å›:
        RegressionReport
    """
    t0 = time.time()
    
    # åŠ è½½æµ‹è¯•é›†
    mgr = GoldenDatasetManager(db_path)
    if mgr.count() == 0:
        mgr.load_defaults()
    
    cases = mgr.list_cases()
    if categories:
        cases = [c for c in cases if c.category in categories]
    
    if not cases:
        return RegressionReport(
            version=version_tag,
            timestamp=datetime.now().isoformat(),
            total_cases=0, results=[], avg_scores={},
            overall_avg=0, keyword_avg=0, elapsed_total_ms=0,
        )
    
    # å¯¼å…¥ judgeï¼ˆå¦‚æœéœ€è¦ï¼‰
    judge_fn = None
    if use_judge:
        try:
            from llm_judge import judge_output
            judge_fn = judge_output
        except ImportError:
            logger.warning("llm_judge.py æœªæ‰¾åˆ°ï¼Œä»…ä½¿ç”¨å…³é”®è¯åŒ¹é…")
    
    # æ‰§è¡Œæµ‹è¯•
    results = []
    dim_totals = {}
    kw_totals = []
    
    for i, case in enumerate(cases):
        logger.info(f"[{i+1}/{len(cases)}] {case.case_id}: {case.question[:40]}...")
        case_t0 = time.time()
        
        # è°ƒç”¨ Agent
        try:
            output = agent_fn(case.question)
            if not isinstance(output, str):
                output = str(output)
        except Exception as e:
            results.append(RegressionResult(
                case_id=case.case_id,
                question=case.question,
                agent_output="",
                scores={},
                keyword_hits=0,
                keyword_total=len(case.expected_keywords),
                keyword_score=0,
                overall_score=0,
                error=str(e),
            ))
            continue
        
        # å…³é”®è¯åŒ¹é…
        hits = sum(1 for kw in case.expected_keywords if kw in output)
        kw_score = hits / len(case.expected_keywords) if case.expected_keywords else 1.0
        kw_totals.append(kw_score)
        
        # LLM-as-Judge è¯„åˆ†
        scores = {}
        if judge_fn and api_key:
            scores = judge_fn(
                question=case.question,
                output=output,
                context="",  # å›å½’æµ‹è¯•ä¸æä¾› contextï¼Œé  Agent è‡ªå·±æ‰¾æ•°æ®
                provider=provider,
                api_key=api_key,
            )
            
            for dim in ["correctness", "relevance", "hallucination"]:
                if dim in scores and scores[dim].get("score", -1) >= 0:
                    if dim not in dim_totals:
                        dim_totals[dim] = []
                    dim_totals[dim].append(scores[dim]["score"])
        
        # ç»¼åˆåˆ†æ•° = LLM è¯„åˆ† * 0.7 + å…³é”®è¯åŒ¹é… * 0.3
        judge_avg = scores.get("overall", kw_score)
        if judge_avg < 0:
            judge_avg = kw_score
        overall = round(judge_avg * 0.7 + kw_score * 0.3, 3)
        
        elapsed = (time.time() - case_t0) * 1000
        
        results.append(RegressionResult(
            case_id=case.case_id,
            question=case.question,
            agent_output=output[:500],
            scores=scores,
            keyword_hits=hits,
            keyword_total=len(case.expected_keywords),
            keyword_score=round(kw_score, 3),
            overall_score=overall,
            elapsed_ms=round(elapsed, 1),
        ))
    
    # æ±‡æ€»
    total_elapsed = (time.time() - t0) * 1000
    avg_scores = {
        dim: round(sum(vals) / len(vals), 3)
        for dim, vals in dim_totals.items()
    }
    overall_avg = round(
        sum(r.overall_score for r in results if not r.error) / max(len([r for r in results if not r.error]), 1),
        3
    )
    keyword_avg = round(sum(kw_totals) / max(len(kw_totals), 1), 3)
    
    report = RegressionReport(
        version=version_tag,
        timestamp=datetime.now().isoformat(),
        total_cases=len(cases),
        results=results,
        avg_scores=avg_scores,
        overall_avg=overall_avg,
        keyword_avg=keyword_avg,
        elapsed_total_ms=round(total_elapsed, 1),
    )
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    run_id = mgr.save_regression_run(report)
    logger.info(f"âœ… å›å½’æµ‹è¯•å®Œæˆ (run #{run_id}): ç‰ˆæœ¬={version_tag}, "
                f"æ€»åˆ†={overall_avg:.2f}, å…³é”®è¯={keyword_avg:.2f}")
    
    return report


def compare_versions(db_path: str = "golden_dataset.db", limit: int = 5) -> str:
    """å¯¹æ¯”æœ€è¿‘å‡ ä¸ªç‰ˆæœ¬çš„å›å½’æµ‹è¯•ç»“æœ"""
    mgr = GoldenDatasetManager(db_path)
    history = mgr.get_regression_history(limit)
    
    if not history:
        return "æš‚æ— å›å½’æµ‹è¯•è®°å½•ã€‚è¿è¡Œ run_regression() ç”Ÿæˆç¬¬ä¸€æ¡ã€‚"
    
    lines = ["ç‰ˆæœ¬å¯¹æ¯”ï¼ˆæœ€è¿‘ {} æ¬¡ï¼‰:".format(len(history))]
    lines.append("-" * 70)
    lines.append(f"{'ç‰ˆæœ¬':<15} {'ç»¼åˆåˆ†':>8} {'å…³é”®è¯':>8} {'ç”¨ä¾‹æ•°':>6} {'è€—æ—¶':>10}")
    lines.append("-" * 70)
    
    for h in history:
        lines.append(
            f"{h['version']:<15} {h['overall_avg']:>8.3f} "
            f"{h['keyword_avg']:>8.3f} {h['total_cases']:>6} "
            f"{h['elapsed_ms']:>8.0f}ms"
        )
    
    # æ£€æµ‹é€€æ­¥
    if len(history) >= 2:
        latest = history[0]
        prev = history[1]
        diff = latest["overall_avg"] - prev["overall_avg"]
        if diff < -0.05:
            lines.append(f"\nâš ï¸  è´¨é‡ä¸‹é™è­¦å‘Š: {latest['version']} æ¯” {prev['version']} "
                        f"é™ä½äº† {abs(diff):.3f}")
        elif diff > 0.05:
            lines.append(f"\nâœ… è´¨é‡æå‡: {latest['version']} æ¯” {prev['version']} "
                        f"æå‡äº† {diff:.3f}")
    
    return "\n".join(lines)


# ============================================================
# CLI
# ============================================================

if __name__ == "__main__":
    import sys
    
    print("=" * 60)
    print("MRARFAI Golden Dataset Manager")
    print("=" * 60)
    
    mgr = GoldenDatasetManager()
    loaded = mgr.load_defaults()
    total = mgr.count()
    
    print(f"âœ… æ•°æ®åº“: golden_dataset.db")
    print(f"   æœ¬æ¬¡æ–°åŠ è½½: {loaded} æ¡")
    print(f"   æ€»æµ‹è¯•ç”¨ä¾‹: {total} æ¡")
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    categories = {}
    for case in mgr.list_cases():
        categories[case.category] = categories.get(case.category, 0) + 1
    
    print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    for cat, count in sorted(categories.items()):
        print(f"   {cat}: {count} æ¡")
    
    # æ˜¾ç¤ºå†å²å¯¹æ¯”
    print(f"\n{compare_versions()}")
    
    if "--list" in sys.argv:
        print(f"\nğŸ“‹ å…¨éƒ¨æµ‹è¯•ç”¨ä¾‹:")
        for case in mgr.list_cases():
            print(f"  [{case.case_id}] ({case.category}/{case.difficulty}) {case.question}")
            print(f"         å…³é”®è¯: {', '.join(case.expected_keywords)}")
